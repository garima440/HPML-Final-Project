{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1bc5f7e814d94a61902ff6731cb0b948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c00bbd3cebc45cf8b23292af23e269c",
              "IPY_MODEL_c88d79bc670b4a528afcbbbd363f0ce6",
              "IPY_MODEL_cbaa18860ff849f993c4a19e82f45b25"
            ],
            "layout": "IPY_MODEL_26a4eaf5fe6a45d795081408a71f5009"
          }
        },
        "8c00bbd3cebc45cf8b23292af23e269c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_598f3d69cebb49c998c7155909b4fdd4",
            "placeholder": "​",
            "style": "IPY_MODEL_bf9c4e8971c34f29a336cf97eb680df9",
            "value": "Map: 100%"
          }
        },
        "c88d79bc670b4a528afcbbbd363f0ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eee45e6fb6e04b64aac0adedf134f2c1",
            "max": 3668,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b0115c82c3540d7b38e285507aec424",
            "value": 3668
          }
        },
        "cbaa18860ff849f993c4a19e82f45b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24ee22bee89f4123a75e802804fc2c2e",
            "placeholder": "​",
            "style": "IPY_MODEL_18e4b498ab574d30b32345a5a9e93bb8",
            "value": " 3668/3668 [00:02&lt;00:00, 1425.75 examples/s]"
          }
        },
        "26a4eaf5fe6a45d795081408a71f5009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "598f3d69cebb49c998c7155909b4fdd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf9c4e8971c34f29a336cf97eb680df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eee45e6fb6e04b64aac0adedf134f2c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b0115c82c3540d7b38e285507aec424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24ee22bee89f4123a75e802804fc2c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e4b498ab574d30b32345a5a9e93bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbe9c0bc069d4647bbaeeef5a89bb87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b12561fc85c4dec92e5657878261ded",
              "IPY_MODEL_96038071c0154deea3da9f356bb9d5ec"
            ],
            "layout": "IPY_MODEL_aad718d76eb5472f8e203d30f416b014"
          }
        },
        "0b12561fc85c4dec92e5657878261ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef450557fcf942d39698b3c2db33e3f7",
            "placeholder": "​",
            "style": "IPY_MODEL_67faea8793a54cbd9013c418513ab7c4",
            "value": "0.027 MB of 0.027 MB uploaded\r"
          }
        },
        "96038071c0154deea3da9f356bb9d5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e1bc5b6557743aeb5d5a2e447e8cea2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29b3d4953da74e6aaa80ef50510d0d3f",
            "value": 1
          }
        },
        "aad718d76eb5472f8e203d30f416b014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef450557fcf942d39698b3c2db33e3f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67faea8793a54cbd9013c418513ab7c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e1bc5b6557743aeb5d5a2e447e8cea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29b3d4953da74e6aaa80ef50510d0d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32851801e2cf48df81b73f02af241192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3c326ed8e07400e9b16dd4f3df8b889",
              "IPY_MODEL_bcf73fe678fe4e18b142e6806867e1b4",
              "IPY_MODEL_4664761fae84474493de0ec78253fb22"
            ],
            "layout": "IPY_MODEL_189a815675a841f9ae46bab41441ca8d"
          }
        },
        "e3c326ed8e07400e9b16dd4f3df8b889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9645b0ad26d485792c08395254a9983",
            "placeholder": "​",
            "style": "IPY_MODEL_3c7ce720c4fd47839f10a1b5c20adbdd",
            "value": "config.json: 100%"
          }
        },
        "bcf73fe678fe4e18b142e6806867e1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7aa78bc57134a3f814be5376fcb8a5b",
            "max": 409,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd6619d25736489ba9be7535659ac934",
            "value": 409
          }
        },
        "4664761fae84474493de0ec78253fb22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fb954d0a739410e819901a06506a1ff",
            "placeholder": "​",
            "style": "IPY_MODEL_dbdd0fa609994d6da2441efe402e33f5",
            "value": " 409/409 [00:00&lt;00:00, 32.6kB/s]"
          }
        },
        "189a815675a841f9ae46bab41441ca8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9645b0ad26d485792c08395254a9983": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c7ce720c4fd47839f10a1b5c20adbdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7aa78bc57134a3f814be5376fcb8a5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd6619d25736489ba9be7535659ac934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fb954d0a739410e819901a06506a1ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbdd0fa609994d6da2441efe402e33f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1188c9949d24a1ca99e51711c585297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df6859fd39734d0dbfe9b6b77e22b51a",
              "IPY_MODEL_347aac2d33d84da2b3c0b3fa6ebd9ef6",
              "IPY_MODEL_e8d3afc3a30242a5adcf8b2d94aa822c"
            ],
            "layout": "IPY_MODEL_c3259b4695664d9b94550db242a57eb8"
          }
        },
        "df6859fd39734d0dbfe9b6b77e22b51a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7966aa36d1ad404485406137fdb4eba6",
            "placeholder": "​",
            "style": "IPY_MODEL_6213075d0b454d459965cb3a71e0af16",
            "value": "vocab.txt: 100%"
          }
        },
        "347aac2d33d84da2b3c0b3fa6ebd9ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48136a374124416c95af711d987c4931",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3dd67556ef384525b4dde7cc8caefada",
            "value": 231508
          }
        },
        "e8d3afc3a30242a5adcf8b2d94aa822c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a797f6fe8d614fb0a74350fd863e3ecb",
            "placeholder": "​",
            "style": "IPY_MODEL_295783e44ee0486fa890ffb60befdeb7",
            "value": " 232k/232k [00:00&lt;00:00, 11.7MB/s]"
          }
        },
        "c3259b4695664d9b94550db242a57eb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7966aa36d1ad404485406137fdb4eba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6213075d0b454d459965cb3a71e0af16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48136a374124416c95af711d987c4931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dd67556ef384525b4dde7cc8caefada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a797f6fe8d614fb0a74350fd863e3ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "295783e44ee0486fa890ffb60befdeb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "204c4862ed924ac1ab034c6f66820c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebf36f3b69a14dc4a20a6e3e2d94128c",
              "IPY_MODEL_9d7594b3bca14ca792bd7a95c23c3f37",
              "IPY_MODEL_092aadc0370444499be1f717a872757f"
            ],
            "layout": "IPY_MODEL_135ab7f8da514b858291f8812c3661a2"
          }
        },
        "ebf36f3b69a14dc4a20a6e3e2d94128c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a37a18fcfa3148078881e9af7b8f5681",
            "placeholder": "​",
            "style": "IPY_MODEL_af4534c0aa4e47458f2f0d0819a866c5",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "9d7594b3bca14ca792bd7a95c23c3f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a06045d24cc4eaa8e53f7c05533cb5e",
            "max": 62747391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_677e37facad44fc885717968dc2f6ad0",
            "value": 62747391
          }
        },
        "092aadc0370444499be1f717a872757f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afdab324c0b54cc489ec4d2b0ad75990",
            "placeholder": "​",
            "style": "IPY_MODEL_02c2c90ab3aa4bddaf2babb8eff68d60",
            "value": " 62.7M/62.7M [00:00&lt;00:00, 208MB/s]"
          }
        },
        "135ab7f8da514b858291f8812c3661a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a37a18fcfa3148078881e9af7b8f5681": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af4534c0aa4e47458f2f0d0819a866c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a06045d24cc4eaa8e53f7c05533cb5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "677e37facad44fc885717968dc2f6ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afdab324c0b54cc489ec4d2b0ad75990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02c2c90ab3aa4bddaf2babb8eff68d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cd7ee44cbf446348a58363afa1d16f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4984ef2d763d44b29bae3cdef47c6f12",
              "IPY_MODEL_43b1cbfb64c5422f9714bfa0cb7e1497",
              "IPY_MODEL_1fb916011a0c4db9b0bf52effd3cfd0b"
            ],
            "layout": "IPY_MODEL_e89b545102e14c4298eb8980403d411c"
          }
        },
        "4984ef2d763d44b29bae3cdef47c6f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76fa385ced9d4ae09b965b4ba7e7995b",
            "placeholder": "​",
            "style": "IPY_MODEL_48ba0b3598324f648bd0cc31daa33615",
            "value": ""
          }
        },
        "43b1cbfb64c5422f9714bfa0cb7e1497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f501289e11441edb1128e4cca9439f9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e74b06209bb34bb7ba2ad0408a855547",
            "value": 0
          }
        },
        "1fb916011a0c4db9b0bf52effd3cfd0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58d32145dd5440ac9bc1fc9db148cf45",
            "placeholder": "​",
            "style": "IPY_MODEL_fa874a499db546b1b2d6277735d4afa1",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "e89b545102e14c4298eb8980403d411c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76fa385ced9d4ae09b965b4ba7e7995b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48ba0b3598324f648bd0cc31daa33615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f501289e11441edb1128e4cca9439f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e74b06209bb34bb7ba2ad0408a855547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58d32145dd5440ac9bc1fc9db148cf45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa874a499db546b1b2d6277735d4afa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65364ac3516847be9ff90056ae559475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72b3a4a5f41042ba84a428d588a9c6b9",
              "IPY_MODEL_79259dcdb45a4d39b6a39eacfcb4ea5b",
              "IPY_MODEL_ec2ee4f12b0142959145f8649a27780d"
            ],
            "layout": "IPY_MODEL_940fdef61298424cae6c45c7e03bdf9a"
          }
        },
        "72b3a4a5f41042ba84a428d588a9c6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ea54a18ed949f2b172b3d80d154e16",
            "placeholder": "​",
            "style": "IPY_MODEL_57a900496ac449f28e1a0d0cf727ab1d",
            "value": "Downloading builder script: 100%"
          }
        },
        "79259dcdb45a4d39b6a39eacfcb4ea5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abb50a3978fd4038ad61bcf6f826843c",
            "max": 5749,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a14f7dc53324461af47f3ee692947b1",
            "value": 5749
          }
        },
        "ec2ee4f12b0142959145f8649a27780d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7d47ca9a5824e679041db35e889d439",
            "placeholder": "​",
            "style": "IPY_MODEL_119a87b56cc44c50ae2c1319426639e5",
            "value": " 5.75k/5.75k [00:00&lt;00:00, 451kB/s]"
          }
        },
        "940fdef61298424cae6c45c7e03bdf9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ea54a18ed949f2b172b3d80d154e16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57a900496ac449f28e1a0d0cf727ab1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abb50a3978fd4038ad61bcf6f826843c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a14f7dc53324461af47f3ee692947b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7d47ca9a5824e679041db35e889d439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "119a87b56cc44c50ae2c1319426639e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef2fd2b49fff47f185f3108acffd0568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d24d45a0bed44539e78ea0c99fc05dc",
              "IPY_MODEL_4e132c9b736c4932945879ffef08600a",
              "IPY_MODEL_b0aeb05b9dcb44b69610cb17dd630f32"
            ],
            "layout": "IPY_MODEL_06e07d44d4b34eb18003caa8129c889e"
          }
        },
        "8d24d45a0bed44539e78ea0c99fc05dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_462f3cb8742a4489a084364f063d4903",
            "placeholder": "​",
            "style": "IPY_MODEL_794fbbe7b19d434885eafa37d81849d1",
            "value": "config.json: 100%"
          }
        },
        "4e132c9b736c4932945879ffef08600a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4a9077690f740c8a0308673e0b27df7",
            "max": 409,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9797f74eaf614021a1c9d149cdec00bf",
            "value": 409
          }
        },
        "b0aeb05b9dcb44b69610cb17dd630f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60ce3fcf379d4078888c0a02bd5aa038",
            "placeholder": "​",
            "style": "IPY_MODEL_6149104ba32d49d5a4d6664a4840b61e",
            "value": " 409/409 [00:00&lt;00:00, 35.2kB/s]"
          }
        },
        "06e07d44d4b34eb18003caa8129c889e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "462f3cb8742a4489a084364f063d4903": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "794fbbe7b19d434885eafa37d81849d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4a9077690f740c8a0308673e0b27df7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9797f74eaf614021a1c9d149cdec00bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60ce3fcf379d4078888c0a02bd5aa038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6149104ba32d49d5a4d6664a4840b61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aa6a4de6be84c9d94f8421e24b1c06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6606ca5f345f4db2b3d76780e4a768b7",
              "IPY_MODEL_214e51ae19c6423eac4b0eda17045f0d",
              "IPY_MODEL_aca0af1979e14a2587e296ed4111f9a2"
            ],
            "layout": "IPY_MODEL_15c68c62fdf24d16804515afd0650f04"
          }
        },
        "6606ca5f345f4db2b3d76780e4a768b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_537fb1a4048b4ad8a1bb0cb701bece6f",
            "placeholder": "​",
            "style": "IPY_MODEL_3c3ffea9117f4b0fbecc8d81082eb4f9",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "214e51ae19c6423eac4b0eda17045f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3e260e9b25c4948aa6851fd5a96272c",
            "max": 62747391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6abe1d1594d8411fb2f8cc2761a147b6",
            "value": 62747391
          }
        },
        "aca0af1979e14a2587e296ed4111f9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46c8d7b4083d4c3ab7df1da2d7134a06",
            "placeholder": "​",
            "style": "IPY_MODEL_0ee6034fce7542729c91ac66964cea1d",
            "value": " 62.7M/62.7M [00:00&lt;00:00, 219MB/s]"
          }
        },
        "15c68c62fdf24d16804515afd0650f04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "537fb1a4048b4ad8a1bb0cb701bece6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c3ffea9117f4b0fbecc8d81082eb4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3e260e9b25c4948aa6851fd5a96272c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6abe1d1594d8411fb2f8cc2761a147b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46c8d7b4083d4c3ab7df1da2d7134a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee6034fce7542729c91ac66964cea1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Efficient Fine Tuning and Inference Optimization for `TinyBert`\n",
        "\n",
        "\n",
        "Welcome to our final project notebook! In this work, we explore the recent integration of `bitsandbytes`, featuring innovative 4-bit quantization techniques by XXX that enable efficient inference and training of large language models without compromising performance.\n",
        "\n",
        "In this notebook, we will demonstrate how to load and fine-tune a large model in 4-bit precision `huawei-noah/TinyBERT_General_4L_312D` using Google Colab and the Hugging Face 🤗 PEFT library. Let’s dive into democratizing LLM inference and training together!\n",
        "\n",
        "\n",
        "\n",
        "This notebook is adapted from [bnb-4bit-integration](https://colab.research.google.com/drive/1ge2F1QSK8Q7h0hn3YKuBCOAS0bK8E0wf?usp=sharing) provided by Hugging Face. It demonstrates techniques for efficient 4-bit quantization to optimize LLM inference and training.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XIyP_0r6zuVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get started, install all the dependencies:"
      ],
      "metadata": {
        "id": "SUqhrRMgapMT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuXIFTFapAMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e02dbf-cfd6-490e-d979-1b53f15acd43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.9)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n",
            "Collecting xformers\n",
            "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.2.post1.tar.gz (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->xformers) (1.3.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->xformers) (3.0.2)\n",
            "Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.2.post1-cp310-cp310-linux_x86_64.whl size=190160474 sha256=0b454d9e650bfc437cc71335080172a5d05f51eab355636c9d5b7321fec7318e\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/ec/5b/b2c37a8e4f755ad82492a822463bca0817f0e0e11de874b550\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: xformers, flash-attn\n",
            "Successfully installed flash-attn-2.7.2.post1 xformers-0.0.28.post3\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q datasets\n",
        "!pip install evaluate\n",
        "!pip install xformers flash-attn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First let's load the model we are going to use - `huawei-noah/TinyBERT_General_4L_312D`! Note that the model itself is around 54.74 MB in full precision."
      ],
      "metadata": {
        "id": "MJ-5idQwzvg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForSequenceClassification\n",
        "\n",
        "model_id = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})"
      ],
      "metadata": {
        "id": "E0Nl5mWL0k2T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276,
          "referenced_widgets": [
            "32851801e2cf48df81b73f02af241192",
            "e3c326ed8e07400e9b16dd4f3df8b889",
            "bcf73fe678fe4e18b142e6806867e1b4",
            "4664761fae84474493de0ec78253fb22",
            "189a815675a841f9ae46bab41441ca8d",
            "f9645b0ad26d485792c08395254a9983",
            "3c7ce720c4fd47839f10a1b5c20adbdd",
            "f7aa78bc57134a3f814be5376fcb8a5b",
            "cd6619d25736489ba9be7535659ac934",
            "2fb954d0a739410e819901a06506a1ff",
            "dbdd0fa609994d6da2441efe402e33f5",
            "b1188c9949d24a1ca99e51711c585297",
            "df6859fd39734d0dbfe9b6b77e22b51a",
            "347aac2d33d84da2b3c0b3fa6ebd9ef6",
            "e8d3afc3a30242a5adcf8b2d94aa822c",
            "c3259b4695664d9b94550db242a57eb8",
            "7966aa36d1ad404485406137fdb4eba6",
            "6213075d0b454d459965cb3a71e0af16",
            "48136a374124416c95af711d987c4931",
            "3dd67556ef384525b4dde7cc8caefada",
            "a797f6fe8d614fb0a74350fd863e3ecb",
            "295783e44ee0486fa890ffb60befdeb7",
            "204c4862ed924ac1ab034c6f66820c1a",
            "ebf36f3b69a14dc4a20a6e3e2d94128c",
            "9d7594b3bca14ca792bd7a95c23c3f37",
            "092aadc0370444499be1f717a872757f",
            "135ab7f8da514b858291f8812c3661a2",
            "a37a18fcfa3148078881e9af7b8f5681",
            "af4534c0aa4e47458f2f0d0819a866c5",
            "3a06045d24cc4eaa8e53f7c05533cb5e",
            "677e37facad44fc885717968dc2f6ad0",
            "afdab324c0b54cc489ec4d2b0ad75990",
            "02c2c90ab3aa4bddaf2babb8eff68d60"
          ]
        },
        "outputId": "f77bc560-71c3-418b-8355-8a46802f2767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/409 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32851801e2cf48df81b73f02af241192"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1188c9949d24a1ca99e51711c585297"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/62.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "204c4862ed924ac1ab034c6f66820c1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we have to apply some preprocessing to the model to prepare it for training. For that use the `prepare_model_for_kbit_training` method from PEFT."
      ],
      "metadata": {
        "id": "Mp2gMi1ZzGET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "a9EUEDAl0ss3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "gkIcwsSU01EB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"query\", \"key\", \"value\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_CLS\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybeyl20n3dYH",
        "outputId": "e1b6f640-5b6a-4766-b66c-ae0fa5f3a5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 120434 || all params: 12146284 || trainable%: 0.9915295904492271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load the GLUE dataset, specifically the MRPC (Microsoft Research Paraphrase Corpus), to fine-tune our model on paraphrase detection."
      ],
      "metadata": {
        "id": "FCc64bfnmd3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Load GLUE dataset (MRPC task)\n",
        "from datasets import load_dataset  # Import the load_dataset function\n",
        "import evaluate\n",
        "\n",
        "\n",
        "task = \"mrpc\"\n",
        "dataset = load_dataset(\"glue\", task)\n",
        "metric = evaluate.load(\"glue\", task)"
      ],
      "metadata": {
        "id": "oBr4lNOYype3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "4cd7ee44cbf446348a58363afa1d16f1",
            "4984ef2d763d44b29bae3cdef47c6f12",
            "43b1cbfb64c5422f9714bfa0cb7e1497",
            "1fb916011a0c4db9b0bf52effd3cfd0b",
            "e89b545102e14c4298eb8980403d411c",
            "76fa385ced9d4ae09b965b4ba7e7995b",
            "48ba0b3598324f648bd0cc31daa33615",
            "9f501289e11441edb1128e4cca9439f9",
            "e74b06209bb34bb7ba2ad0408a855547",
            "58d32145dd5440ac9bc1fc9db148cf45",
            "fa874a499db546b1b2d6277735d4afa1",
            "65364ac3516847be9ff90056ae559475",
            "72b3a4a5f41042ba84a428d588a9c6b9",
            "79259dcdb45a4d39b6a39eacfcb4ea5b",
            "ec2ee4f12b0142959145f8649a27780d",
            "940fdef61298424cae6c45c7e03bdf9a",
            "76ea54a18ed949f2b172b3d80d154e16",
            "57a900496ac449f28e1a0d0cf727ab1d",
            "abb50a3978fd4038ad61bcf6f826843c",
            "3a14f7dc53324461af47f3ee692947b1",
            "b7d47ca9a5824e679041db35e889d439",
            "119a87b56cc44c50ae2c1319426639e5"
          ]
        },
        "outputId": "a81f66bf-c66b-46e8-84f9-81f6b7618ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cd7ee44cbf446348a58363afa1d16f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.75k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65364ac3516847be9ff90056ae559475"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import transformers\n",
        "\n",
        "# 4. Define compute_metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)  # Convert logits to predicted class\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "ad_JohvDysmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up W&B sweeps\n",
        "================="
      ],
      "metadata": {
        "id": "RiiJSVlxdJZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "3c4SGknzJuwh",
        "outputId": "4838da2b-8830-4af9-9547-325e5827a158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'random',\n",
        "    'metric': {\n",
        "        'name': 'accuracy',  # Track accuracy as the metric for saving the best model\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'optimizer': {\n",
        "            'values': ['adamw_torch', 'adafactor', 'adamw_hf', 'adamw_8bit', 'sgd']\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'distribution': 'log_uniform_values',\n",
        "            'min': 1e-5,\n",
        "            'max': 1e-3\n",
        "        },\n",
        "        'lr_scheduler': {\n",
        "            'values': [\n",
        "                'linear',\n",
        "                'cosine',\n",
        "                'constant',\n",
        "                'constant_with_warmup',\n",
        "                'polynomial'\n",
        "            ]\n",
        "        },\n",
        "        'weight_decay': {\n",
        "            'values': [0.0, 0.01, 0.001, 0.1]\n",
        "        },\n",
        "        'warmup_ratio': {\n",
        "            'values': [0.05, 0.1, 0.15, 0.2]\n",
        "        },\n",
        "        'train_batch_size': {\n",
        "            'values': [8, 16, 32, 64, 128]\n",
        "        },\n",
        "        'gradient_accumulation_steps': {\n",
        "            'values': [2, 4, 8, 32, 64]\n",
        "        },\n",
        "        'lora_r': {\n",
        "            'values': [8, 16, 32, 64, 128]\n",
        "        },\n",
        "        'lora_alpha': {\n",
        "            'values': [4, 8, 16, 32, 64]\n",
        "        },\n",
        "        'lora_dropout': {\n",
        "            'values': [0.05, 0.1, 0.2]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "SZ-apE95J4At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"TinyBert 101\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ekru6UmKbcu",
        "outputId": "a96c3cba-d7fd-471c-87ae-4e07a1714867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: pbit4fos\n",
            "Sweep URL: https://wandb.ai/garima440-new-york-university/TinyBert%20101/sweeps/pbit4fos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to run the training! For the sake of the demo, we just ran it for 1 count."
      ],
      "metadata": {
        "id": "_0MOtwf3zdZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a padding token for the tokenizer\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})  # Add a padding token\n",
        "\n",
        "# 3. Preprocessing function for tokenization\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"sentence1\"],\n",
        "        examples[\"sentence2\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",  # Ensure uniform input size\n",
        "        max_length=512,       # Typical BERT max length\n",
        "    )\n",
        "\n",
        "# 4. Tokenize dataset\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# 5. Data collator\n",
        "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "def train(config=None):\n",
        "    # Initialize a new wandb run\n",
        "    with wandb.init(config=config):\n",
        "        # If called by wandb.agent, as below,\n",
        "        # this config will be set by Sweep Controller\n",
        "        config = wandb.config\n",
        "\n",
        "        # 6. Define Trainer with TrainingArguments\n",
        "        trainer = transformers.Trainer(\n",
        "            model=model,\n",
        "            train_dataset=encoded_dataset[\"train\"],\n",
        "            eval_dataset=encoded_dataset[\"validation\"],\n",
        "            tokenizer=tokenizer,\n",
        "            data_collator=data_collator,\n",
        "            args=transformers.TrainingArguments(\n",
        "                per_device_train_batch_size=config.train_batch_size,  # BERT can handle larger batch sizes\n",
        "                gradient_accumulation_steps=config.gradient_accumulation_steps,  # Adjust if GPU memory is limited\n",
        "                warmup_ratio=config.warmup_ratio,\n",
        "                max_steps=300,\n",
        "                learning_rate=config.learning_rate,\n",
        "                fp16=True,  # Enable mixed-precision if supported by your hardware\n",
        "                logging_steps=50,\n",
        "                evaluation_strategy=\"steps\",  # Evaluate periodically\n",
        "                output_dir=\"./outputs\",\n",
        "                save_steps=100,\n",
        "                save_total_limit=2,  # Keep only the latest 2 checkpoints\n",
        "                optim=config.optimizer,\n",
        "                weight_decay=config.weight_decay,\n",
        "                lr_scheduler_type=config.lr_scheduler,\n",
        "            ),\n",
        "                compute_metrics=compute_metrics,\n",
        "\n",
        "        )\n",
        "\n",
        "        # 7. Disable caching for training\n",
        "        model.config.use_cache = False\n",
        "\n",
        "        # 8. Train the model\n",
        "        trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1bc5f7e814d94a61902ff6731cb0b948",
            "8c00bbd3cebc45cf8b23292af23e269c",
            "c88d79bc670b4a528afcbbbd363f0ce6",
            "cbaa18860ff849f993c4a19e82f45b25",
            "26a4eaf5fe6a45d795081408a71f5009",
            "598f3d69cebb49c998c7155909b4fdd4",
            "bf9c4e8971c34f29a336cf97eb680df9",
            "eee45e6fb6e04b64aac0adedf134f2c1",
            "3b0115c82c3540d7b38e285507aec424",
            "24ee22bee89f4123a75e802804fc2c2e",
            "18e4b498ab574d30b32345a5a9e93bb8"
          ]
        },
        "id": "jq0nX33BmfaC",
        "outputId": "753fc2e8-7fe4-4571-dd8a-48edbeb8490b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bc5f7e814d94a61902ff6731cb0b948"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, train, count=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cbe9c0bc069d4647bbaeeef5a89bb87d",
            "0b12561fc85c4dec92e5657878261ded",
            "96038071c0154deea3da9f356bb9d5ec",
            "aad718d76eb5472f8e203d30f416b014",
            "ef450557fcf942d39698b3c2db33e3f7",
            "67faea8793a54cbd9013c418513ab7c4",
            "4e1bc5b6557743aeb5d5a2e447e8cea2",
            "29b3d4953da74e6aaa80ef50510d0d3f"
          ]
        },
        "id": "20q8rwxnL4hS",
        "outputId": "e60d19f9-129b-4998-f4a6-837935eabe23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m65nty3u with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003916496770060197\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: polynomial\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adafactor\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241209_021228-m65nty3u</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20101/runs/m65nty3u' target=\"_blank\">jolly-sweep-2</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20101' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20101/sweeps/pbit4fos' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20101/sweeps/pbit4fos</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20101' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20101</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20101/sweeps/pbit4fos' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20101/sweeps/pbit4fos</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20101/runs/m65nty3u' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20101/runs/m65nty3u</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-15-3801201518a6>:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = transformers.Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 18:37, Epoch 20/22]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.661800</td>\n",
              "      <td>0.652600</td>\n",
              "      <td>0.683824</td>\n",
              "      <td>0.812227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.602400</td>\n",
              "      <td>0.572950</td>\n",
              "      <td>0.681373</td>\n",
              "      <td>0.810496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.532400</td>\n",
              "      <td>0.499376</td>\n",
              "      <td>0.789216</td>\n",
              "      <td>0.857616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.482300</td>\n",
              "      <td>0.458111</td>\n",
              "      <td>0.813725</td>\n",
              "      <td>0.875410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.459700</td>\n",
              "      <td>0.434768</td>\n",
              "      <td>0.821078</td>\n",
              "      <td>0.877311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.439700</td>\n",
              "      <td>0.430333</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>0.879195</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.027 MB of 0.027 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbe9c0bc069d4647bbaeeef5a89bb87d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▆███</td></tr><tr><td>eval/f1</td><td>▁▁▆███</td></tr><tr><td>eval/loss</td><td>█▅▃▂▁▁</td></tr><tr><td>eval/runtime</td><td>▂▂█▆▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▇▇▁▃▇█</td></tr><tr><td>eval/steps_per_second</td><td>▇▇▁▃▇█</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▄▄▅▅▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▄▄▅▅▇▇███</td></tr><tr><td>train/grad_norm</td><td>▃▁▁█▃▆</td></tr><tr><td>train/learning_rate</td><td>██▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▆▄▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.82353</td></tr><tr><td>eval/f1</td><td>0.87919</td></tr><tr><td>eval/loss</td><td>0.43033</td></tr><tr><td>eval/runtime</td><td>2.234</td></tr><tr><td>eval/samples_per_second</td><td>182.635</td></tr><tr><td>eval/steps_per_second</td><td>22.829</td></tr><tr><td>total_flos</td><td>1079050000465920.0</td></tr><tr><td>train/epoch</td><td>20</td></tr><tr><td>train/global_step</td><td>300</td></tr><tr><td>train/grad_norm</td><td>0.51951</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4397</td></tr><tr><td>train_loss</td><td>0.52971</td></tr><tr><td>train_runtime</td><td>1122.4856</td></tr><tr><td>train_samples_per_second</td><td>68.42</td></tr><tr><td>train_steps_per_second</td><td>0.267</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">jolly-sweep-2</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20101/runs/m65nty3u' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20101/runs/m65nty3u</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20101' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20101</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241209_021228-m65nty3u/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running inference on fine-tuned and optimized model\n",
        "==================================================="
      ],
      "metadata": {
        "id": "rUfNuf05dhPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run this cell if you load the model files as zip\n",
        "!unzip fine-tuned-model.zip -d fine-tuned-model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86atNvfBcTI2",
        "outputId": "8113943b-4bac-40fc-9cb6-4ab961ab42db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  fine-tuned-model.zip\n",
            "  inflating: fine-tuned-model/model_files_HPML_accuracy_82/special_tokens_map.json  \n",
            "  inflating: fine-tuned-model/model_files_HPML_accuracy_82/README.md  \n",
            "  inflating: fine-tuned-model/model_files_HPML_accuracy_82/scheduler.pt  \n",
            "  inflating: fine-tuned-model/model_files_HPML_accuracy_82/adapter_model.safetensors  \n",
            "  inflating: fine-tuned-model/model_files_HPML_accuracy_82/vocab.txt  \n",
            "  inflating: fine-tuned-model/model_files_HPML_accuracy_82/adapter_config.json  \n",
            "  inflating: fine-tuned-model/model_files_HPML_accuracy_82/tokenizer_config.json  \n",
            "  inflating: fine-tuned-model/model_files_HPML_accuracy_82/rng_state.pth  \n",
            "  inflating: fine-tuned-model/model_files_HPML_accuracy_82/tokenizer.json  \n",
            "  inflating: fine-tuned-model/model_files_HPML_accuracy_82/training_args.bin  \n",
            "  inflating: fine-tuned-model/model_files_HPML_accuracy_82/trainer_state.json  \n",
            "  inflating: fine-tuned-model/model_files_HPML_accuracy_82/optimizer.pt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the fine tuned model and move it to CUDA\n",
        "--------------------------------------------"
      ],
      "metadata": {
        "id": "tl8RoJ7qeEts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import time\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"fine-tuned-model/model-files\")\n",
        "\n",
        "# Load tokenizer and trained model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"fine-tuned-model/model-files\")  # Path to your saved model\n",
        "model.eval()  # Set to evaluation mode\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ef2fd2b49fff47f185f3108acffd0568",
            "8d24d45a0bed44539e78ea0c99fc05dc",
            "4e132c9b736c4932945879ffef08600a",
            "b0aeb05b9dcb44b69610cb17dd630f32",
            "06e07d44d4b34eb18003caa8129c889e",
            "462f3cb8742a4489a084364f063d4903",
            "794fbbe7b19d434885eafa37d81849d1",
            "f4a9077690f740c8a0308673e0b27df7",
            "9797f74eaf614021a1c9d149cdec00bf",
            "60ce3fcf379d4078888c0a02bd5aa038",
            "6149104ba32d49d5a4d6664a4840b61e",
            "7aa6a4de6be84c9d94f8421e24b1c06f",
            "6606ca5f345f4db2b3d76780e4a768b7",
            "214e51ae19c6423eac4b0eda17045f0d",
            "aca0af1979e14a2587e296ed4111f9a2",
            "15c68c62fdf24d16804515afd0650f04",
            "537fb1a4048b4ad8a1bb0cb701bece6f",
            "3c3ffea9117f4b0fbecc8d81082eb4f9",
            "c3e260e9b25c4948aa6851fd5a96272c",
            "6abe1d1594d8411fb2f8cc2761a147b6",
            "46c8d7b4083d4c3ab7df1da2d7134a06",
            "0ee6034fce7542729c91ac66964cea1d"
          ]
        },
        "id": "fia_dJBybdbm",
        "outputId": "846e99ff-4c70-4213-aaaa-18711dc7ea48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/409 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef2fd2b49fff47f185f3108acffd0568"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/62.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7aa6a4de6be84c9d94f8421e24b1c06f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 312, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 312)\n",
              "      (token_type_embeddings): Embedding(2, 312)\n",
              "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-3): 4 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): lora.Linear(\n",
              "                (base_layer): Linear(in_features=312, out_features=312, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=312, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=312, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (key): lora.Linear(\n",
              "                (base_layer): Linear(in_features=312, out_features=312, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=312, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=312, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (value): lora.Linear(\n",
              "                (base_layer): Linear(in_features=312, out_features=312, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=312, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=312, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=312, out_features=1200, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=1200, out_features=312, bias=True)\n",
              "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): ModulesToSaveWrapper(\n",
              "    (original_module): Linear(in_features=312, out_features=2, bias=True)\n",
              "    (modules_to_save): ModuleDict(\n",
              "      (default): Linear(in_features=312, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XosP70hYVXNF",
        "outputId": "89b62a59-7e4f-450e-b367-7b5bcc20333c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 312, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 312)\n",
              "      (token_type_embeddings): Embedding(2, 312)\n",
              "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-3): 4 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): lora.Linear(\n",
              "                (base_layer): Linear(in_features=312, out_features=312, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=312, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=312, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (key): lora.Linear(\n",
              "                (base_layer): Linear(in_features=312, out_features=312, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=312, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=312, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (value): lora.Linear(\n",
              "                (base_layer): Linear(in_features=312, out_features=312, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=312, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=312, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=312, out_features=1200, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=1200, out_features=312, bias=True)\n",
              "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): ModulesToSaveWrapper(\n",
              "    (original_module): Linear(in_features=312, out_features=2, bias=True)\n",
              "    (modules_to_save): ModuleDict(\n",
              "      (default): Linear(in_features=312, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference Profiling using Flash Attention ONLY\n",
        "---------------------------------------------"
      ],
      "metadata": {
        "id": "sVFPYAGvkf9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following code imports necessary libraries for model inference, including PyTorch, transformers for tokenization and model loading, flash attention for efficient attention mechanisms, and datasets for handling datasets. The `prepare_batch_inputs` function tokenizes pairs of input texts, ensuring they are padded, truncated, and moved to the appropriate device for model processing."
      ],
      "metadata": {
        "id": "3Dza1qVeed3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from flash_attn import flash_attn_func\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "def prepare_batch_inputs(texts1, texts2):\n",
        "    \"\"\"\n",
        "    Prepare batch of input tokens and attention masks\n",
        "\n",
        "    :param texts: List of input texts to process\n",
        "    :return: Tokenized batch inputs\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(\n",
        "        texts1, texts2,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    # Move inputs to the same device as the model\n",
        "    return {k: v.to(device) for k, v in inputs.items()}"
      ],
      "metadata": {
        "id": "kQ7lvUw7Q1J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function is the custom implementation of Flash Attention. It reshapes the tensor, applies attention using `flash_attn_func`, and then restores the output to its original form. A turbo boost for attention layers, it's designed to handle TinyBERT’s architecture with precision and speed, all while keeping data in float16 for performance."
      ],
      "metadata": {
        "id": "pz4FTkiSerop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_flash_attention(hidden_states):\n",
        "    \"\"\"\n",
        "    Apply Flash Attention to the input batch\n",
        "\n",
        "    :param hidden_states: Hidden states tensor\n",
        "    :return: Attention output\n",
        "    \"\"\"\n",
        "    # Reshape hidden_states to (batch_size, sequence_length, num_heads, head_dim)\n",
        "    batch_size, seq_len, hidden_size = hidden_states.shape  # Get the original shape\n",
        "    num_heads = 12\n",
        "    head_dim = hidden_size // num_heads\n",
        "\n",
        "    # Reshape for Flash Attention (batch_size, seq_len, num_heads, head_dim)\n",
        "    hidden_states = hidden_states.reshape(batch_size, seq_len, num_heads, head_dim)\n",
        "\n",
        "    # Cast hidden_states to float16 before applying Flash Attention\n",
        "    hidden_states = hidden_states.type(torch.float16)\n",
        "\n",
        "    # Apply Flash Attention\n",
        "    q, k, v = hidden_states, hidden_states, hidden_states\n",
        "    attn_output = flash_attn_func(q, k, v, dropout_p=0.0)\n",
        "\n",
        "    # Reshape back to the original shape (batch_size, seq_len, hidden_size)\n",
        "    attn_output = attn_output.reshape(batch_size, seq_len, hidden_size)\n",
        "\n",
        "    # Cast attn_output back to the original dtype if necessary\n",
        "    attn_output = attn_output.type(hidden_states.dtype)\n",
        "\n",
        "    return attn_output"
      ],
      "metadata": {
        "id": "cumohr69RhRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function handles batch inference on a dataset, processing each batch through our model to get predictions. It tracks inference time per batch and calculates performance metrics such as latency and sample throughput. For each batch, the function extracts text pairs, prepares inputs, applies `Flash Attention` on hidden states, and computes softmax probabilities. After processing, it returns the predictions and a dictionary with performance statistics."
      ],
      "metadata": {
        "id": "eVqib9KifGZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_inference(dataset, batch_size):\n",
        "    inference_times = []\n",
        "    all_predictions = []\n",
        "\n",
        "    # Iterate through dataset in batches\n",
        "    for i in range(0, len(dataset), batch_size):\n",
        "        # Get the batch (select 'sentence1' and 'sentence2' columns)\n",
        "        batch = dataset[i : i + batch_size]\n",
        "\n",
        "        # Extract texts from the batch\n",
        "        batch_texts1 = batch['sentence1']\n",
        "        batch_texts2 = batch['sentence2']\n",
        "\n",
        "        inputs = prepare_batch_inputs(batch_texts1, batch_texts2)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        start_time = time.time()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(\n",
        "                input_ids=inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask'],\n",
        "                output_hidden_states=True,\n",
        "            )\n",
        "\n",
        "            hidden_states = outputs.hidden_states[-1]\n",
        "            attention_output = apply_flash_attention(hidden_states)\n",
        "            logits = model.classifier(attention_output.mean(dim=1).type(torch.float32))\n",
        "            probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        end_time = time.time()\n",
        "        batch_inference_time = end_time - start_time\n",
        "        inference_times.append(batch_inference_time)\n",
        "\n",
        "        all_predictions.extend(probabilities.cpu().numpy())\n",
        "\n",
        "    performance_metrics = {\n",
        "        'total_samples': len(dataset),\n",
        "        'batch_size': batch_size,\n",
        "        'device': str(device),\n",
        "        'inference_times': inference_times,\n",
        "        'avg_batch_latency_ms': np.mean(inference_times) * 1000,\n",
        "        'std_batch_latency_ms': np.std(inference_times) * 1000,\n",
        "        'avg_sample_latency_ms': (np.mean(inference_times) * 1000) / batch_size\n",
        "    }\n",
        "\n",
        "    return all_predictions, performance_metrics\n"
      ],
      "metadata": {
        "id": "uplcsNcERm4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select test set\n",
        "test_dataset = dataset['test']\n",
        "\n",
        "# Configuration\n",
        "batch_sizes = [32, 64, 128, 512, 1024]\n",
        "\n",
        "for batch in batch_sizes:\n",
        "\n",
        "    # Perform batch inference on test set\n",
        "    all_predictions, performance_metrics = batch_inference(test_dataset, batch)\n",
        "\n",
        "    # Print performance metrics\n",
        "    print(\"\\n--- Batch Inference Performance Metrics ---\")\n",
        "    for metric, value in performance_metrics.items():\n",
        "        print(f\"{metric}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nmr4RaaPP7mC",
        "outputId": "7b4ad2ff-1444-4c15-9cb2-12e92f1bb81c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Batch Inference Performance Metrics ---\n",
            "total_samples: 1725\n",
            "batch_size: 32\n",
            "device: cuda\n",
            "inference_times: [0.00932002067565918, 0.006934165954589844, 0.0069463253021240234, 0.00872182846069336, 0.006987094879150391, 0.00688624382019043, 0.008557319641113281, 0.0065784454345703125, 0.006702899932861328, 0.006498098373413086, 0.009231328964233398, 0.0065708160400390625, 0.007443904876708984, 0.006562471389770508, 0.0064852237701416016, 0.006543159484863281, 0.006667375564575195, 0.0066373348236083984, 0.006604194641113281, 0.0065975189208984375, 0.006800413131713867, 0.0066988468170166016, 0.006528615951538086, 0.006893157958984375, 0.00730586051940918, 0.0065572261810302734, 0.006543636322021484, 0.00662684440612793, 0.008111000061035156, 0.007271766662597656, 0.0065920352935791016, 0.006590843200683594, 0.006611347198486328, 0.006510734558105469, 0.006804704666137695, 0.006814241409301758, 0.008165121078491211, 0.008106708526611328, 0.006478548049926758, 0.006487369537353516, 0.0065195560455322266, 0.006489992141723633, 0.008118867874145508, 0.008162260055541992, 0.008141040802001953, 0.00808405876159668, 0.008066177368164062, 0.006474733352661133, 0.006459236145019531, 0.006592512130737305, 0.0065920352935791016, 0.007402658462524414, 0.008111238479614258, 0.008037328720092773]\n",
            "avg_batch_latency_ms: 7.133823853951913\n",
            "std_batch_latency_ms: 0.7845067780507523\n",
            "avg_sample_latency_ms: 0.2229319954359973\n",
            "\n",
            "--- Batch Inference Performance Metrics ---\n",
            "total_samples: 1725\n",
            "batch_size: 64\n",
            "device: cuda\n",
            "inference_times: [0.008391857147216797, 0.008362293243408203, 0.008573055267333984, 0.010049819946289062, 0.00838160514831543, 0.009376049041748047, 0.008376598358154297, 0.008095264434814453, 0.008616209030151367, 0.008349895477294922, 0.008302450180053711, 0.0072748661041259766, 0.007702827453613281, 0.008012056350708008, 0.0070917606353759766, 0.008842229843139648, 0.00712895393371582, 0.007149934768676758, 0.007647037506103516, 0.007258415222167969, 0.008263111114501953, 0.007339000701904297, 0.007756233215332031, 0.007244586944580078, 0.007493019104003906, 0.006937265396118164, 0.007509708404541016]\n",
            "avg_batch_latency_ms: 7.982448295310692\n",
            "std_batch_latency_ms: 0.7368030046584977\n",
            "avg_sample_latency_ms: 0.12472575461422956\n",
            "\n",
            "--- Batch Inference Performance Metrics ---\n",
            "total_samples: 1725\n",
            "batch_size: 128\n",
            "device: cuda\n",
            "inference_times: [0.012454032897949219, 0.015581369400024414, 0.014114141464233398, 0.012434244155883789, 0.01374506950378418, 0.013745546340942383, 0.013218402862548828, 0.015040874481201172, 0.011838436126708984, 0.012773513793945312, 0.013752937316894531, 0.01291346549987793, 0.012514114379882812, 0.006997108459472656]\n",
            "avg_batch_latency_ms: 12.937375477382115\n",
            "std_batch_latency_ms: 1.9279447015519016\n",
            "avg_sample_latency_ms: 0.10107324591704778\n",
            "\n",
            "--- Batch Inference Performance Metrics ---\n",
            "total_samples: 1725\n",
            "batch_size: 512\n",
            "device: cuda\n",
            "inference_times: [0.056786298751831055, 0.05457305908203125, 0.04978823661804199, 0.017864465713500977]\n",
            "avg_batch_latency_ms: 44.75301504135132\n",
            "std_batch_latency_ms: 15.728800996105859\n",
            "avg_sample_latency_ms: 0.0874082325026393\n",
            "\n",
            "--- Batch Inference Performance Metrics ---\n",
            "total_samples: 1725\n",
            "batch_size: 1024\n",
            "device: cuda\n",
            "inference_times: [0.10918259620666504, 0.0671544075012207]\n",
            "avg_batch_latency_ms: 88.16850185394287\n",
            "std_batch_latency_ms: 21.014094352722168\n",
            "avg_sample_latency_ms: 0.08610205259174109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.profiler import profile, ProfilerActivity, record_function\n",
        "\n",
        "def profile_inference_latency(dataset, batch_size):\n",
        "        \"\"\"\n",
        "        Use PyTorch Profiler to measure inference latency\n",
        "        \"\"\"\n",
        "        # Take a small subset of the dataset for profiling\n",
        "        batch = dataset[:batch_size]\n",
        "        batch_texts1 = batch['sentence1']\n",
        "        batch_texts2 = batch['sentence2']\n",
        "\n",
        "        inputs = prepare_batch_inputs(batch_texts1, batch_texts2)\n",
        "\n",
        "        with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "                     on_trace_ready=torch.profiler.tensorboard_trace_handler(\"./profiler_logs\"),\n",
        "                     record_shapes=True, with_stack=True) as prof:\n",
        "            with record_function(\"model_inference\"):\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(\n",
        "                        input_ids=inputs['input_ids'],\n",
        "                        attention_mask=inputs['attention_mask'],\n",
        "                        output_hidden_states=True\n",
        "                    )\n",
        "\n",
        "                    hidden_states = outputs.hidden_states[-1]\n",
        "                    attention_output = apply_flash_attention(hidden_states)\n",
        "                    logits = model.classifier(attention_output.mean(dim=1).type(torch.float32))\n",
        "                    probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "        print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "id": "WzdXikL-eVhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference Benchmarking with PyTorch Profiler\n",
        "--------------------------------------------------\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EgnCmp5TnxW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform PyTorch profiler on test set\n",
        "# Configuration\n",
        "batch_sizes = [32, 64, 128, 512, 1024]\n",
        "\n",
        "for batch in batch_sizes:\n",
        "    print(f\"\\n--- PyTorch Profiler with batch size {batch} ---\")\n",
        "    profile_inference_latency(test_dataset, batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLxBeJnxQA96",
        "outputId": "4b634ffb-6ab9-45d4-9cd6-0745e887ba4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- PyTorch Profiler with batch size 32 ---\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      16.491ms       374.77%      16.491ms      16.491ms             1  \n",
            "                                        model_inference        44.82%       9.166ms        99.94%      20.438ms      20.438ms       0.000us         0.00%       4.400ms       4.400ms             1  \n",
            "                                           aten::linear         1.85%     377.896us        19.72%       4.034ms      79.090us       0.000us         0.00%       2.743ms      53.781us            51  \n",
            "                                            aten::addmm         5.87%       1.201ms         7.78%       1.591ms      58.939us       2.454ms        55.78%       2.454ms      90.904us            27  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.796ms        40.81%       1.796ms      56.122us            32  \n",
            "                     aten::scaled_dot_product_attention         0.37%      75.359us        11.56%       2.365ms     591.166us       0.000us         0.00%       1.069ms     267.248us             4  \n",
            "               aten::_scaled_dot_product_attention_math         0.52%     106.042us        11.19%       2.289ms     572.326us       0.000us         0.00%       1.069ms     267.248us             4  \n",
            "                                           aten::matmul         2.23%     455.411us        12.26%       2.507ms      78.341us       0.000us         0.00%     925.315us      28.916us            32  \n",
            "                                ampere_sgemm_128x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     715.166us        16.25%     715.166us     178.791us             4  \n",
            "                                              aten::bmm         1.17%     238.494us         1.50%     306.473us      38.309us     524.574us        11.92%     524.574us      65.572us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 20.450ms\n",
            "Self CUDA time total: 4.400ms\n",
            "\n",
            "\n",
            "--- PyTorch Profiler with batch size 64 ---\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      15.466ms       203.21%      15.466ms      15.466ms             1  \n",
            "                                        model_inference        41.23%       7.162ms        99.94%      17.359ms      17.359ms       0.000us         0.00%       7.611ms       7.611ms             1  \n",
            "                                           aten::linear         1.96%     340.277us        20.54%       3.568ms      69.954us       0.000us         0.00%       4.658ms      91.326us            51  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       4.375ms        57.48%       4.375ms     121.525us            36  \n",
            "                                            aten::addmm         6.27%       1.090ms         8.42%       1.462ms      54.157us       4.278ms        56.21%       4.278ms     158.432us            27  \n",
            "                     aten::scaled_dot_product_attention         0.26%      45.744us        12.79%       2.222ms     555.575us       0.000us         0.00%       1.998ms     499.591us             4  \n",
            "               aten::_scaled_dot_product_attention_math         0.57%      99.532us        12.53%       2.177ms     544.140us       0.000us         0.00%       1.998ms     499.591us             4  \n",
            "                                           aten::matmul         1.96%     340.458us        13.08%       2.271ms      70.979us       0.000us         0.00%       1.557ms      48.662us            32  \n",
            "                                              aten::bmm         1.31%     227.047us         1.76%     304.893us      38.112us     999.166us        13.13%     999.166us     124.896us             8  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     999.166us        13.13%     999.166us     124.896us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 17.370ms\n",
            "Self CUDA time total: 7.611ms\n",
            "\n",
            "\n",
            "--- PyTorch Profiler with batch size 128 ---\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      16.599ms       114.92%      16.599ms      16.599ms             1  \n",
            "                                        model_inference        43.75%       8.710ms        95.65%      19.042ms      19.042ms       0.000us         0.00%      14.443ms      14.443ms             1  \n",
            "                                           aten::linear         1.82%     361.810us        18.80%       3.743ms      73.390us       0.000us         0.00%       8.642ms     169.456us            51  \n",
            "                                            aten::addmm         5.60%       1.114ms         7.61%       1.515ms      56.102us       8.103ms        56.10%       8.103ms     300.106us            27  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       5.716ms        39.58%       5.716ms     285.806us            20  \n",
            "                     aten::scaled_dot_product_attention         0.24%      47.843us        11.52%       2.294ms     573.453us       0.000us         0.00%       3.960ms     989.998us             4  \n",
            "               aten::_scaled_dot_product_attention_math         0.49%      98.270us        11.28%       2.246ms     561.492us       0.000us         0.00%       3.960ms     989.998us             4  \n",
            "                                           aten::matmul         1.94%     386.794us        11.67%       2.322ms      72.571us       0.000us         0.00%       2.853ms      89.146us            32  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us       2.336ms        16.18%       2.336ms     584.079us             4  \n",
            "                                              aten::bmm         1.14%     227.748us         1.53%     303.756us      37.970us       1.955ms        13.54%       1.955ms     244.368us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 19.908ms\n",
            "Self CUDA time total: 14.443ms\n",
            "\n",
            "\n",
            "--- PyTorch Profiler with batch size 512 ---\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      69.135ms       101.16%      69.135ms      69.135ms             1  \n",
            "                                        model_inference        11.61%       8.414ms        25.71%      18.636ms      18.636ms       0.000us         0.00%      68.344ms      68.344ms             1  \n",
            "                                           aten::linear         0.47%     339.027us         4.90%       3.553ms      69.674us       0.000us         0.00%      39.102ms     766.701us            51  \n",
            "                                            aten::addmm         1.56%       1.130ms         2.08%       1.511ms      55.953us      37.109ms        54.30%      37.109ms       1.374ms            27  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      26.842ms        39.28%      26.842ms     838.825us            32  \n",
            "                     aten::scaled_dot_product_attention         0.07%      47.794us         3.02%       2.192ms     547.902us       0.000us         0.00%      19.381ms       4.845ms             4  \n",
            "               aten::_scaled_dot_product_attention_math         0.12%      88.582us         2.96%       2.144ms     535.954us       0.000us         0.00%      19.381ms       4.845ms             4  \n",
            "                                  ampere_sgemm_64x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      12.202ms        17.85%      12.202ms     762.623us            16  \n",
            "                                           aten::matmul         0.43%     309.567us         3.02%       2.191ms      68.483us       0.000us         0.00%      11.850ms     370.318us            32  \n",
            "                                              aten::bmm         0.37%     269.835us         0.46%     334.444us      41.806us       8.200ms        12.00%       8.200ms       1.025ms             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 72.496ms\n",
            "Self CUDA time total: 68.344ms\n",
            "\n",
            "\n",
            "--- PyTorch Profiler with batch size 1024 ---\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us     132.900ms       100.48%     132.900ms     132.900ms             1  \n",
            "                                        model_inference         5.97%       8.109ms        14.39%      19.558ms      19.558ms       0.000us         0.00%     132.272ms     132.272ms             1  \n",
            "                                           aten::linear         0.26%     356.113us         2.67%       3.630ms      71.178us       0.000us         0.00%      74.382ms       1.458ms            51  \n",
            "                                  ampere_sgemm_64x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      72.085ms        54.50%      72.085ms       2.002ms            36  \n",
            "                                            aten::addmm         0.83%       1.122ms         1.11%       1.506ms      55.791us      70.704ms        53.45%      70.704ms       2.619ms            27  \n",
            "                     aten::scaled_dot_product_attention         0.03%      47.267us         1.79%       2.439ms     609.691us       0.000us         0.00%      38.417ms       9.604ms             4  \n",
            "               aten::_scaled_dot_product_attention_math         0.07%      99.402us         1.76%       2.391ms     597.875us       0.000us         0.00%      38.417ms       9.604ms             4  \n",
            "                                           aten::matmul         0.26%     348.330us         1.73%       2.351ms      73.456us       0.000us         0.00%      23.234ms     726.063us            32  \n",
            "                                              aten::bmm         0.17%     233.593us         0.22%     299.325us      37.416us      16.292ms        12.32%      16.292ms       2.037ms             8  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us      16.292ms        12.32%      16.292ms       2.037ms             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 135.906ms\n",
            "Self CUDA time total: 132.272ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference profiling using Flash Attention + KV caching\n",
        "-------------------------------------------------------"
      ],
      "metadata": {
        "id": "jr46itjah9uf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This time we are performing inference with `KV caching` in combination with `flash attention` to evaluate potential performance optimizations by leveraging cached keys and values for more efficient attention computation."
      ],
      "metadata": {
        "id": "d03tfxX9obMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from flash_attn import flash_attn_func\n",
        "from datasets import Dataset\n",
        "\n",
        "class InferenceModel:\n",
        "    def __init__(self, model, tokenizer, device):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "        self.past_key_values = None\n",
        "\n",
        "    def prepare_batch_inputs(self, texts1, texts2):\n",
        "        \"\"\"\n",
        "        Prepare batch of input tokens and attention masks.\n",
        "        :param texts1: List of input texts\n",
        "        :param texts2: List of input texts\n",
        "        :return: Tokenized batch inputs\n",
        "        \"\"\"\n",
        "        inputs = self.tokenizer(\n",
        "            texts1, texts2,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "        return {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "    def apply_flash_attention(self, hidden_states, past_key_values=None):\n",
        "        \"\"\"\n",
        "        Apply Flash Attention to the input batch with KV caching.\n",
        "\n",
        "        :param hidden_states: Hidden states tensor (current input)\n",
        "        :param past_key_values: Cached keys and values from previous steps\n",
        "        :return: Attention output, updated past_key_values\n",
        "        \"\"\"\n",
        "        # Reshape hidden_states to (batch_size, sequence_length, num_heads, head_dim)\n",
        "        batch_size, seq_len, hidden_size = hidden_states.shape  # Get the original shape\n",
        "        num_heads = 12\n",
        "        head_dim = hidden_size // num_heads\n",
        "\n",
        "        # Reshape for Flash Attention (batch_size, seq_len, num_heads, head_dim)\n",
        "        hidden_states = hidden_states.reshape(batch_size, seq_len, num_heads, head_dim)\n",
        "\n",
        "        # Cast hidden_states to float16 before applying Flash Attention\n",
        "        hidden_states = hidden_states.type(torch.float16)\n",
        "\n",
        "        # Initialize past_key_values if they are not provided\n",
        "        if past_key_values is None:\n",
        "            past_key_values = (None, None)  # Initialize empty cache\n",
        "\n",
        "        # Use past keys and values, if available, for efficient computation\n",
        "        k, v = past_key_values\n",
        "\n",
        "        # If no past keys/values, use the current hidden states for k and v\n",
        "        if k is None or v is None:\n",
        "            k, v = hidden_states, hidden_states\n",
        "        else:\n",
        "            # Concatenate new keys/values with the past ones (for autoregressive tasks)\n",
        "            k = torch.cat((k, hidden_states), dim=1)  # Concatenate along the sequence dimension\n",
        "            v = torch.cat((v, hidden_states), dim=1)\n",
        "\n",
        "        # Apply Flash Attention with cached keys and values\n",
        "        q = hidden_states  # Query is always the current hidden states\n",
        "        attn_output = flash_attn_func(q, k, v, dropout_p=0.0)\n",
        "\n",
        "        # Reshape back to the original shape (batch_size, seq_len, hidden_size)\n",
        "        attn_output = attn_output.reshape(batch_size, seq_len, hidden_size)\n",
        "\n",
        "        # Cast attn_output back to the original dtype if necessary\n",
        "        attn_output = attn_output.type(hidden_states.dtype)\n",
        "\n",
        "        # Return attention output and updated cached keys/values\n",
        "        return attn_output, (k, v)\n",
        "\n",
        "\n",
        "    def batch_inference(self, dataset, batch_size):\n",
        "        inference_times = []\n",
        "        all_predictions = []\n",
        "\n",
        "        for i in range(0, len(dataset), batch_size):\n",
        "            batch = dataset[i: i + batch_size]\n",
        "            batch_texts1 = batch['sentence1']\n",
        "            batch_texts2 = batch['sentence2']\n",
        "\n",
        "            inputs = self.prepare_batch_inputs(batch_texts1, batch_texts2)\n",
        "\n",
        "            torch.cuda.synchronize()\n",
        "            start_time = time.time()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(\n",
        "                    input_ids=inputs['input_ids'],\n",
        "                    attention_mask=inputs['attention_mask'],\n",
        "                    output_hidden_states=True,\n",
        "                )\n",
        "\n",
        "                hidden_states = outputs.hidden_states[-1]\n",
        "                # Apply Flash Attention with KV caching support\n",
        "                attention_output, _ = self.apply_flash_attention(hidden_states)\n",
        "                logits = self.model.classifier(attention_output.mean(dim=1).type(torch.float32))\n",
        "                probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "            torch.cuda.synchronize()\n",
        "            end_time = time.time()\n",
        "            batch_inference_time = end_time - start_time\n",
        "            inference_times.append(batch_inference_time)\n",
        "\n",
        "            all_predictions.extend(probabilities.cpu().numpy())\n",
        "\n",
        "        performance_metrics = {\n",
        "            'total_samples': len(dataset),\n",
        "            'batch_size': batch_size,\n",
        "            'device': str(self.device),\n",
        "            'inference_times': inference_times,\n",
        "            'avg_batch_latency_ms': np.mean(inference_times) * 1000,\n",
        "            'std_batch_latency_ms': np.std(inference_times) * 1000,\n",
        "            'avg_sample_latency_ms': (np.mean(inference_times) * 1000) / batch_size\n",
        "        }\n",
        "\n",
        "        return all_predictions, performance_metrics\n"
      ],
      "metadata": {
        "id": "DYw8RNx9jqYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.config.use_cache = True\n",
        "inference_model = InferenceModel(model=model, tokenizer=tokenizer, device=device)\n",
        "\n",
        "batch_sizes = [32, 64, 128, 512, 1024]\n",
        "\n",
        "for batch in batch_sizes:\n",
        "    all_predictions, performance_metrics = inference_model.batch_inference(dataset[\"test\"], batch_size=batch)\n",
        "\n",
        "    for metric, value in performance_metrics.items():\n",
        "            print(f\"{metric}: {value}\")\n",
        "    print(\"\\n---\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqo84q-OkC3c",
        "outputId": "f4f42727-a01f-4a2e-9281-8c83916ddb7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_samples: 1725\n",
            "batch_size: 32\n",
            "device: cuda\n",
            "inference_times: [0.008347272872924805, 0.006960391998291016, 0.006997823715209961, 0.006956577301025391, 0.006833553314208984, 0.0068645477294921875, 0.007044076919555664, 0.006682395935058594, 0.006621122360229492, 0.0066111087799072266, 0.006586551666259766, 0.006570339202880859, 0.006794929504394531, 0.006838560104370117, 0.006660938262939453, 0.006474494934082031, 0.006488323211669922, 0.006643533706665039, 0.006551504135131836, 0.006559848785400391, 0.00655364990234375, 0.006518840789794922, 0.010175466537475586, 0.006676435470581055, 0.006707906723022461, 0.006567955017089844, 0.0064737796783447266, 0.006512165069580078, 0.007138490676879883, 0.006635904312133789, 0.006411552429199219, 0.0066967010498046875, 0.0069310665130615234, 0.006721973419189453, 0.006443977355957031, 0.006539344787597656, 0.0064661502838134766, 0.006536960601806641, 0.00652003288269043, 0.006426811218261719, 0.0066106319427490234, 0.0066525936126708984, 0.006688356399536133, 0.006523609161376953, 0.006606578826904297, 0.0066068172454833984, 0.006850481033325195, 0.006838321685791016, 0.0067903995513916016, 0.0066089630126953125, 0.006972551345825195, 0.006595134735107422, 0.007109165191650391, 0.006620168685913086]\n",
            "avg_batch_latency_ms: 6.774385770161946\n",
            "std_batch_latency_ms: 0.5484266208396699\n",
            "avg_sample_latency_ms: 0.21169955531756082\n",
            "\n",
            "---\n",
            "\n",
            "total_samples: 1725\n",
            "batch_size: 64\n",
            "device: cuda\n",
            "inference_times: [0.007848501205444336, 0.008141040802001953, 0.008328437805175781, 0.009786128997802734, 0.008584737777709961, 0.008498430252075195, 0.007596254348754883, 0.007380485534667969, 0.00781559944152832, 0.008398056030273438, 0.008367776870727539, 0.007357120513916016, 0.007766008377075195, 0.008776187896728516, 0.007174968719482422, 0.008935213088989258, 0.00720977783203125, 0.00955963134765625, 0.007631778717041016, 0.0069272518157958984, 0.008082389831542969, 0.007150411605834961, 0.00751042366027832, 0.007111787796020508, 0.007300376892089844, 0.006824016571044922, 0.006980180740356445]\n",
            "avg_batch_latency_ms: 7.8904805360017\n",
            "std_batch_latency_ms: 0.7726989305441625\n",
            "avg_sample_latency_ms: 0.12328875837502656\n",
            "\n",
            "---\n",
            "\n",
            "total_samples: 1725\n",
            "batch_size: 128\n",
            "device: cuda\n",
            "inference_times: [0.012392520904541016, 0.015567302703857422, 0.014034748077392578, 0.012379884719848633, 0.013783931732177734, 0.013765335083007812, 0.013229608535766602, 0.015130043029785156, 0.011853456497192383, 0.012760162353515625, 0.013831853866577148, 0.012896299362182617, 0.012529611587524414, 0.006972551345825195]\n",
            "avg_batch_latency_ms: 12.937664985656738\n",
            "std_batch_latency_ms: 1.9415978851501638\n",
            "avg_sample_latency_ms: 0.10107550770044327\n",
            "\n",
            "---\n",
            "\n",
            "total_samples: 1725\n",
            "batch_size: 512\n",
            "device: cuda\n",
            "inference_times: [0.05668234825134277, 0.05447983741760254, 0.04965400695800781, 0.018063783645629883]\n",
            "avg_batch_latency_ms: 44.71999406814575\n",
            "std_batch_latency_ms: 15.598481473343455\n",
            "avg_sample_latency_ms: 0.08734373841434717\n",
            "\n",
            "---\n",
            "\n",
            "total_samples: 1725\n",
            "batch_size: 1024\n",
            "device: cuda\n",
            "inference_times: [0.10930442810058594, 0.0670166015625]\n",
            "avg_batch_latency_ms: 88.16051483154297\n",
            "std_batch_latency_ms: 21.14391326904297\n",
            "avg_sample_latency_ms: 0.08609425276517868\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion\n",
        "===========\n",
        "We enhanced `TinyBERT's` performance on the `GLUE` \"MRPC\" task by adding a `LoRA adapter` and applying `quantization-aware training`, which resulted in an accuracy increase from **~40% to 82%** on the validation set. To optimize inference, we experimented with techniques like `Flash Attention` and `KV caching`. Flash Attention led to significant improvements in inference efficiency. However, when combined with KV caching, there was no notable performance gain, likely because KV caching is more beneficial for sequence-to-sequence tasks, whereas MRPC is a classification task."
      ],
      "metadata": {
        "id": "pkNIilxqo4G1"
      }
    }
  ]
}