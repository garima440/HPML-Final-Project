{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30805,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers accelerate bitsandbytes datasets torch-tb-profiler peft evaluate"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-07T04:26:08.638045Z",
          "iopub.execute_input": "2024-12-07T04:26:08.638894Z",
          "iopub.status.idle": "2024-12-07T04:26:18.462025Z",
          "shell.execute_reply.started": "2024-12-07T04:26:08.638857Z",
          "shell.execute_reply": "2024-12-07T04:26:18.460893Z"
        },
        "id": "deRQf11kcJ4l",
        "outputId": "54e9d1f3-8e9f-442f-a930-3c7da720ab11"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.1.1)\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.45.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\nRequirement already satisfied: torch-tb-profiler in /opt/conda/lib/python3.10/site-packages (0.4.3)\nRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.14.0)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: tensorboard!=2.1.0,>=1.15 in /opt/conda/lib/python3.10/site-packages (from torch-tb-profiler) (2.16.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard!=2.1.0,>=1.15->torch-tb-profiler) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard!=2.1.0,>=1.15->torch-tb-profiler) (1.62.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard!=2.1.0,>=1.15->torch-tb-profiler) (3.6)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard!=2.1.0,>=1.15->torch-tb-profiler) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard!=2.1.0,>=1.15->torch-tb-profiler) (70.0.0)\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard!=2.1.0,>=1.15->torch-tb-profiler) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard!=2.1.0,>=1.15->torch-tb-profiler) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard!=2.1.0,>=1.15->torch-tb-profiler) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "from evaluate import load\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "import time\n",
        "\n",
        "# Load TinyBERT model and tokenizer for GLUE (MNLI task)\n",
        "model_name = \"huawei-noah/TinyBERT_General_4L_312D\"  # Change to \"huawei-noah/TinyBERT_General_4L_312D\" for TinyBERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=3,  # MNLI has 3 classes: \"entailment\", \"neutral\", \"contradiction\"\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "model.eval()\n",
        "\n",
        "# Load the GLUE MNLI dataset\n",
        "dataset = load_dataset(\"glue\", \"mnli\", split=\"validation_matched[:100]\")  # Use a subset for profiling\n",
        "metric = load(\"glue\", \"mnli\")\n",
        "\n",
        "# Preprocess the input data for MNLI\n",
        "def preprocess(example):\n",
        "    inputs = tokenizer(\n",
        "        example[\"premise\"],\n",
        "        example[\"hypothesis\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    inputs[\"labels\"] = torch.tensor(example[\"label\"]).unsqueeze(0)  # Add label tensor\n",
        "    return inputs\n",
        "\n",
        "# Process the dataset\n",
        "inputs = [preprocess(dataset[i]) for i in range(len(dataset))]\n",
        "\n",
        "# Move model and inputs to GPU (if available)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "# Step 1: Baseline Inference Latency Profiling\n",
        "print(\"Running inference latency profiling...\")\n",
        "with torch.no_grad():\n",
        "    start_time = time.time()\n",
        "    for input_data in inputs:\n",
        "        input_data = {k: v.to(device) for k, v in input_data.items()}\n",
        "        outputs = model(**input_data)\n",
        "    end_time = time.time()\n",
        "    print(f\"Inference Latency: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "# Step 2: Detailed Profiling with PyTorch Profiler\n",
        "print(\"\\nRunning detailed profiling...\")\n",
        "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "             record_shapes=True, with_stack=True) as prof:\n",
        "    with torch.no_grad():\n",
        "        for input_data in inputs:\n",
        "            with record_function(\"model_inference\"):\n",
        "                outputs = model(**{k: v.to(device) for k, v in input_data.items()})\n",
        "\n",
        "# Print the profiling results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
        "prof.export_chrome_trace(\"glue_mnli_profiler_trace.json\")\n",
        "print(\"Profiler data saved to glue_mnli_profiler_trace.json\")\n",
        "\n",
        "# Step 3: Compute Accuracy\n",
        "print(\"\\nComputing accuracy...\")\n",
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for input_data in inputs:\n",
        "        input_data = {k: v.to(device) for k, v in input_data.items()}\n",
        "        outputs = model(**input_data)\n",
        "        logits = outputs.logits\n",
        "        predictions.append(torch.argmax(logits, dim=-1).cpu().item())\n",
        "        labels.append(input_data[\"labels\"].cpu().item())\n",
        "\n",
        "accuracy = metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "print(f\"Accuracy on GLUE (MNLI) dataset: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-07T04:28:47.937792Z",
          "iopub.execute_input": "2024-12-07T04:28:47.93876Z",
          "iopub.status.idle": "2024-12-07T04:29:18.520409Z",
          "shell.execute_reply.started": "2024-12-07T04:28:47.938719Z",
          "shell.execute_reply": "2024-12-07T04:29:18.519522Z"
        },
        "id": "lCnYLn7QcJ4m",
        "outputId": "99103c18-d871-438a-bae0-9ea986810461"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Running inference latency profiling...\nInference Latency: 0.6742 seconds\n\nRunning detailed profiling...\n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us     628.758ms        73.54%     628.758ms       6.288ms           100  \n                                        model_inference        39.82%     260.339ms       100.00%     653.734ms       6.537ms       0.000us         0.00%     226.176ms       2.262ms           100  \n                                           aten::linear         3.71%      24.239ms        26.06%     170.338ms      65.514us       0.000us         0.00%     135.162ms      51.985us          2600  \n                                            aten::addmm        12.33%      80.600ms        17.16%     112.164ms      43.140us     135.162ms        15.81%     135.162ms      51.985us          2600  \n                                maxwell_sgemm_128x32_tn         0.00%       0.000us         0.00%       0.000us       0.000us     102.055ms        11.94%     102.055ms      51.027us          2000  \n                     aten::scaled_dot_product_attention         1.05%       6.844ms         5.87%      38.388ms      95.970us       0.000us         0.00%      68.074ms     170.186us           400  \n          aten::_scaled_dot_product_efficient_attention         0.70%       4.591ms         4.47%      29.246ms      73.116us       0.000us         0.00%      68.074ms     170.186us           400  \n                     aten::_efficient_attention_forward         1.26%       8.236ms         3.04%      19.857ms      49.642us      68.074ms         7.96%      68.074ms     170.186us           400  \nfmha_cutlassF_f32_aligned_64x64_rf_sm50(PyTorchMemEf...         0.00%       0.000us         0.00%       0.000us       0.000us      68.074ms         7.96%      68.074ms     170.186us           400  \n                                maxwell_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      30.897ms         3.61%      30.897ms      77.243us           400  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \nSelf CPU time total: 653.744ms\nSelf CUDA time total: 854.934ms\n\nProfiler data saved to glue_mnli_profiler_trace.json\n\nComputing accuracy...\nAccuracy on GLUE (MNLI) dataset: 0.5000\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -Uq"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T19:48:57.55285Z",
          "iopub.execute_input": "2024-12-06T19:48:57.553235Z",
          "iopub.status.idle": "2024-12-06T19:49:05.83465Z",
          "shell.execute_reply.started": "2024-12-06T19:48:57.553201Z",
          "shell.execute_reply": "2024-12-06T19:49:05.833731Z"
        },
        "id": "N2QNWPoVcJ4n",
        "outputId": "7f905f4c-a22a-49c3-c602-9f63a5ffd9eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "    }\n",
        "\n",
        "metric = {\n",
        "    'name': 'loss',\n",
        "    'goal': 'minimize'\n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric\n",
        "\n",
        "parameters_dict = {\n",
        "    # Optimizer Selection\n",
        "    'optimizer': {\n",
        "        'values': ['adamw_torch', 'adafactor', 'adamw_hf', 'adamw_8bit']\n",
        "    },\n",
        "\n",
        "    'learning_rate': {\n",
        "        'distribution': 'log_uniform_values',\n",
        "        'min': 1e-5,\n",
        "        'max': 1e-3\n",
        "    },\n",
        "\n",
        "    # Learning Rate Scheduler\n",
        "    'lr_scheduler': {\n",
        "        'values': [\n",
        "            'linear',\n",
        "            'cosine',\n",
        "            'cosine_with_restarts',\n",
        "            'polynomial',\n",
        "            'constant',\n",
        "            'constant_with_warmup'\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    # Weight Decay\n",
        "    'weight_decay': {\n",
        "        'values': [0.0, 0.01, 0.001, 0.1]\n",
        "    },\n",
        "\n",
        "    # Warm-up Steps (as a percentage of total training steps)\n",
        "    'warmup_ratio': {\n",
        "        'values': [0.0, 0.05, 0.1, 0.15]\n",
        "    },\n",
        "\n",
        "    # Batch Size\n",
        "    'train_batch_size': {\n",
        "        'values': [4, 8, 16, 32]\n",
        "    },\n",
        "\n",
        "    'gradient_accumulation_steps': {\n",
        "        'values' : [2, 4, 8, 16, 32]\n",
        "    },\n",
        "\n",
        "    # LoRA Hyperparameters\n",
        "    'lora_r': {\n",
        "        'values': [8, 16, 32]\n",
        "    },\n",
        "    'lora_alpha': {\n",
        "        'values': [8, 16, 32]\n",
        "    },\n",
        "    'lora_dropout': {\n",
        "        'values': [0.05, 0.1, 0.15]\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T19:49:07.85121Z",
          "iopub.execute_input": "2024-12-06T19:49:07.851565Z",
          "iopub.status.idle": "2024-12-06T19:49:28.0195Z",
          "shell.execute_reply.started": "2024-12-06T19:49:07.851535Z",
          "shell.execute_reply": "2024-12-06T19:49:28.018648Z"
        },
        "id": "lH7ysEtBcJ4n",
        "outputId": "f2411f71-d384-403b-e450-bb5c46f292f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "  ········\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"TinyBert with GLUE on Kaggle\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T19:49:49.441021Z",
          "iopub.execute_input": "2024-12-06T19:49:49.441759Z",
          "iopub.status.idle": "2024-12-06T19:49:49.767687Z",
          "shell.execute_reply.started": "2024-12-06T19:49:49.441726Z",
          "shell.execute_reply": "2024-12-06T19:49:49.766884Z"
        },
        "id": "DjJAFLoQcJ4n",
        "outputId": "6baec203-1b10-469d-ea1c-24f1bdc1f261"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Create sweep with ID: giymvsf9\nSweep URL: https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from datasets import load_dataset\n",
        "from evaluate import load\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import os\n",
        "import wandb\n",
        "from transformers.integrations import WandbCallback\n",
        "from transformers.trainer_callback import TrainerCallback\n",
        "\n",
        "# Load TinyBERT model and tokenizer\n",
        "model_name = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=3,  # MNLI has 3 classes\n",
        "    ignore_mismatched_sizes=True,\n",
        "    torch_dtype=torch.float32  # Explicitly set to float32\n",
        ")\n",
        "\n",
        "global_best_accuracy = 0\n",
        "global_best_model_checkpoint = \"./global_best_model\"\n",
        "\n",
        "class SaveBestAcrossSweepsCallback(TrainerCallback):\n",
        "    def __init__(self, metric_name=\"eval_accuracy\"):\n",
        "        self.metric_name = metric_name\n",
        "        self.last_eval_metrics = None\n",
        "\n",
        "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
        "        # Store the latest evaluation metrics\n",
        "        self.last_eval_metrics = metrics\n",
        "        print(f\"Evaluation Metrics: {metrics}\")\n",
        "\n",
        "    def on_train_end(self, args, state, control, **kwargs):\n",
        "        global global_best_accuracy, global_best_model_checkpoint\n",
        "\n",
        "        # Use the stored evaluation metrics\n",
        "        if self.last_eval_metrics:\n",
        "            current_accuracy = self.last_eval_metrics.get(self.metric_name, 0)\n",
        "            print(f\"Sweep Evaluation Accuracy: {current_accuracy:.4f}\")\n",
        "\n",
        "            if current_accuracy > global_best_accuracy:\n",
        "                global_best_accuracy = current_accuracy\n",
        "                print(f\"New global best {self.metric_name} found: {current_accuracy:.4f}\")\n",
        "\n",
        "                # Save the best model and tokenizer\n",
        "                model = kwargs.get('model')\n",
        "                if model:\n",
        "                    try:\n",
        "                        model.save_pretrained(global_best_model_checkpoint)\n",
        "                        tokenizer.save_pretrained(global_best_model_checkpoint)\n",
        "\n",
        "                        # Log the best model to wandb\n",
        "                        if wandb.run:\n",
        "                            wandb.save(os.path.join(global_best_model_checkpoint, \"*\"))\n",
        "\n",
        "                        print(f\"Global best model saved to {global_best_model_checkpoint}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error saving global best model: {e}\")\n",
        "        else:\n",
        "            print(\"No evaluation metrics found for this sweep.\")\n",
        "\n",
        "def train(config=None):\n",
        "    global model\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "\n",
        "        lora_config = LoraConfig(\n",
        "            r=config.lora_r,\n",
        "            lora_alpha=config.lora_alpha,\n",
        "            target_modules=[\"query\", \"value\"],\n",
        "            lora_dropout=config.lora_dropout,\n",
        "            bias=\"none\",\n",
        "            task_type=\"SEQ_CLS\"\n",
        "        )\n",
        "\n",
        "        model = get_peft_model(model, lora_config)\n",
        "        model.to(\"cuda\")\n",
        "\n",
        "\n",
        "        train_dataset = load_dataset(\"glue\", \"mnli\", split=\"train[:20000]\")\n",
        "        validation_dataset = load_dataset(\"glue\", \"mnli\", split=\"validation_matched[:5000]\")\n",
        "\n",
        "        def preprocess_function(examples):\n",
        "            inputs = tokenizer(\n",
        "                examples[\"premise\"],\n",
        "                examples[\"hypothesis\"],\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                max_length=512\n",
        "            )\n",
        "            inputs[\"labels\"] = examples[\"label\"]\n",
        "            return inputs\n",
        "\n",
        "        train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=train_dataset.column_names)\n",
        "        validation_dataset = validation_dataset.map(preprocess_function, batched=True, remove_columns=validation_dataset.column_names)\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=\"./results\",\n",
        "            num_train_epochs=5,  # Each sweep is 5 epochs\n",
        "            per_device_train_batch_size=config.train_batch_size,\n",
        "            per_device_eval_batch_size=32,\n",
        "            warmup_ratio=config.warmup_ratio,\n",
        "            weight_decay=config.weight_decay,\n",
        "            logging_dir=\"./logs\",\n",
        "            logging_steps=10,\n",
        "            evaluation_strategy=\"epoch\",\n",
        "            save_strategy=\"no\",  # Disable default saving\n",
        "            load_best_model_at_end=False,\n",
        "            metric_for_best_model=\"accuracy\",\n",
        "            gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
        "            learning_rate=config.learning_rate,\n",
        "            lr_scheduler_type=config.lr_scheduler,\n",
        "            fp16=True,\n",
        "            bf16=False\n",
        "        )\n",
        "\n",
        "        metric = load(\"glue\", \"mnli\")\n",
        "\n",
        "        def compute_metrics(eval_pred):\n",
        "            logits, labels = eval_pred\n",
        "            predictions = torch.argmax(torch.from_numpy(logits), dim=-1)\n",
        "            return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=validation_dataset,\n",
        "            compute_metrics=compute_metrics,\n",
        "            callbacks=[SaveBestAcrossSweepsCallback(), WandbCallback()]\n",
        "        )\n",
        "\n",
        "        model.print_trainable_parameters()\n",
        "\n",
        "        trainer.train()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T19:53:58.127829Z",
          "iopub.execute_input": "2024-12-06T19:53:58.128893Z",
          "iopub.status.idle": "2024-12-06T19:53:59.019873Z",
          "shell.execute_reply.started": "2024-12-06T19:53:58.12886Z",
          "shell.execute_reply": "2024-12-06T19:53:59.019265Z"
        },
        "id": "ZjcfFbXfcJ4o",
        "outputId": "d27c8601-7051-4a97-e930-c4ccc45edbcb"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, train, count=20)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T19:54:02.753884Z",
          "iopub.execute_input": "2024-12-06T19:54:02.754243Z",
          "iopub.status.idle": "2024-12-06T23:51:58.996761Z",
          "shell.execute_reply.started": "2024-12-06T19:54:02.754206Z",
          "shell.execute_reply": "2024-12-06T23:51:58.996109Z"
        },
        "id": "CZUcaOOGcJ4o",
        "outputId": "d440271a-8bf7-4d01-f795-ad03c3d6df3b",
        "colab": {
          "referenced_widgets": [
            ""
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: at3hhe3k with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004486513370893436\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: constant\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_hf\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_195404-at3hhe3k</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/at3hhe3k' target=\"_blank\">helpful-sweep-7</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/at3hhe3k' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/at3hhe3k</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "You are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 80,811 || all params: 14,431,998 || trainable%: 0.5599\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='780' max='780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [780/780 11:32, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.805800</td>\n      <td>0.774015</td>\n      <td>0.738600</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.675800</td>\n      <td>0.658774</td>\n      <td>0.751800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.618000</td>\n      <td>0.624771</td>\n      <td>0.764200</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.601600</td>\n      <td>0.607433</td>\n      <td>0.764800</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 0.7740150094032288, 'eval_accuracy': 0.7386, 'eval_runtime': 11.9832, 'eval_samples_per_second': 417.25, 'eval_steps_per_second': 13.102, 'epoch': 0.9984}\nEvaluation Metrics: {'eval_loss': 0.65877366065979, 'eval_accuracy': 0.7518, 'eval_runtime': 11.9728, 'eval_samples_per_second': 417.612, 'eval_steps_per_second': 13.113, 'epoch': 1.9968}\nEvaluation Metrics: {'eval_loss': 0.6247705817222595, 'eval_accuracy': 0.7642, 'eval_runtime': 12.0067, 'eval_samples_per_second': 416.434, 'eval_steps_per_second': 13.076, 'epoch': 2.9952}\nEvaluation Metrics: {'eval_loss': 0.611847460269928, 'eval_accuracy': 0.7618, 'eval_runtime': 12.0064, 'eval_samples_per_second': 416.443, 'eval_steps_per_second': 13.076, 'epoch': 4.0}\nEvaluation Metrics: {'eval_loss': 0.6074326038360596, 'eval_accuracy': 0.7648, 'eval_runtime': 12.0649, 'eval_samples_per_second': 414.427, 'eval_steps_per_second': 13.013, 'epoch': 4.992}\nSweep Evaluation Accuracy: 0.7648\nNew global best eval_accuracy found: 0.7648\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 7 files into the W&B run directory, call wandb.save again to sync new files.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Global best model saved to ./global_best_model\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(Label(value='1.245 MB of 1.245 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▅▅██▇▇██</td></tr><tr><td>eval/loss</td><td>██▃▃▂▂▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▂▂▁▁▄▄▄▄██</td></tr><tr><td>eval/samples_per_second</td><td>▇▇██▅▅▅▅▁▁</td></tr><tr><td>eval/steps_per_second</td><td>▇▇██▅▅▅▅▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇█</td></tr><tr><td>train/grad_norm</td><td>▁▁▁▂▂▂▂▂▂▂▂▃▃▄▃▃▃▃▃▃█▆▆▄▄▄▃▃▃▃▅▃▄▄▃▆▄▅▅▇</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▆▆▆▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▂▁▁▁▁▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.7648</td></tr><tr><td>eval/loss</td><td>0.60743</td></tr><tr><td>eval/runtime</td><td>12.0649</td></tr><tr><td>eval/samples_per_second</td><td>414.427</td></tr><tr><td>eval/steps_per_second</td><td>13.013</td></tr><tr><td>total_flos</td><td>1456486801735680.0</td></tr><tr><td>train/epoch</td><td>4.992</td></tr><tr><td>train/global_step</td><td>780</td></tr><tr><td>train/grad_norm</td><td>13.93696</td></tr><tr><td>train/learning_rate</td><td>0.00045</td></tr><tr><td>train/loss</td><td>0.6016</td></tr><tr><td>train_loss</td><td>0.70322</td></tr><tr><td>train_runtime</td><td>693.5611</td></tr><tr><td>train_samples_per_second</td><td>144.183</td></tr><tr><td>train_steps_per_second</td><td>1.125</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">helpful-sweep-7</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/at3hhe3k' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/at3hhe3k</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 7 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_195404-at3hhe3k/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: np0swwew with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5.02978480871983e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: constant_with_warmup\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_hf\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_200553-np0swwew</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/np0swwew' target=\"_blank\">dazzling-sweep-8</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/np0swwew' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/np0swwew</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 40,875 || all params: 14,392,062 || trainable%: 0.2840\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='780' max='780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [780/780 11:07, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.096600</td>\n      <td>1.097332</td>\n      <td>0.368400</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.080800</td>\n      <td>1.081196</td>\n      <td>0.473600</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.057800</td>\n      <td>1.056182</td>\n      <td>0.483800</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.010300</td>\n      <td>1.006100</td>\n      <td>0.528000</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 1.0973318815231323, 'eval_accuracy': 0.3684, 'eval_runtime': 10.7726, 'eval_samples_per_second': 464.139, 'eval_steps_per_second': 14.574, 'epoch': 0.9984}\nEvaluation Metrics: {'eval_loss': 1.0811959505081177, 'eval_accuracy': 0.4736, 'eval_runtime': 10.8074, 'eval_samples_per_second': 462.644, 'eval_steps_per_second': 14.527, 'epoch': 1.9968}\nEvaluation Metrics: {'eval_loss': 1.0561820268630981, 'eval_accuracy': 0.4838, 'eval_runtime': 10.8367, 'eval_samples_per_second': 461.397, 'eval_steps_per_second': 14.488, 'epoch': 2.9952}\nEvaluation Metrics: {'eval_loss': 1.0323957204818726, 'eval_accuracy': 0.5056, 'eval_runtime': 10.7353, 'eval_samples_per_second': 465.754, 'eval_steps_per_second': 14.625, 'epoch': 4.0}\nEvaluation Metrics: {'eval_loss': 1.0060999393463135, 'eval_accuracy': 0.528, 'eval_runtime': 10.7253, 'eval_samples_per_second': 466.186, 'eval_steps_per_second': 14.638, 'epoch': 4.992}\nSweep Evaluation Accuracy: 0.5280\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▆▆▆▆▇▇██</td></tr><tr><td>eval/loss</td><td>██▇▇▅▅▃▃▁▁</td></tr><tr><td>eval/runtime</td><td>▄▄▆▆██▂▂▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▅▅▃▃▁▁▇▇██</td></tr><tr><td>eval/steps_per_second</td><td>▅▅▃▃▁▁▇▇██</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>▃▁▂▃▄▃▃▂▂▂▂▂▂▂▂▂▄▄▃▄▄▅▃▄▃▅▆▆▄▆▄▄▄▅▄▆▇█▅▅</td></tr><tr><td>train/learning_rate</td><td>▁▂▂▄▆███████████████████████████████████</td></tr><tr><td>train/loss</td><td>███████████▇▇▇▇▇▇▆▆▆▅▅▅▄▄▄▃▄▄▃▃▃▃▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.528</td></tr><tr><td>eval/loss</td><td>1.0061</td></tr><tr><td>eval/runtime</td><td>10.7253</td></tr><tr><td>eval/samples_per_second</td><td>466.186</td></tr><tr><td>eval/steps_per_second</td><td>14.638</td></tr><tr><td>total_flos</td><td>1444238091878400.0</td></tr><tr><td>train/epoch</td><td>4.992</td></tr><tr><td>train/global_step</td><td>780</td></tr><tr><td>train/grad_norm</td><td>3.45456</td></tr><tr><td>train/learning_rate</td><td>5e-05</td></tr><tr><td>train/loss</td><td>1.0103</td></tr><tr><td>train_loss</td><td>1.06478</td></tr><tr><td>train_runtime</td><td>667.8903</td></tr><tr><td>train_samples_per_second</td><td>149.725</td></tr><tr><td>train_steps_per_second</td><td>1.168</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">dazzling-sweep-8</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/np0swwew' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/np0swwew</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_200553-np0swwew/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wssi7orj with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003996381106320194\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: cosine\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_8bit\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_201716-wssi7orj</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/wssi7orj' target=\"_blank\">crisp-sweep-9</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/wssi7orj' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/wssi7orj</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 80,811 || all params: 14,431,998 || trainable%: 0.5599\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3125/3125 10:31, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.919800</td>\n      <td>0.868355</td>\n      <td>0.614000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.821700</td>\n      <td>0.745674</td>\n      <td>0.681800</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.712000</td>\n      <td>0.705342</td>\n      <td>0.702200</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.710100</td>\n      <td>0.689738</td>\n      <td>0.712400</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.755900</td>\n      <td>0.689632</td>\n      <td>0.711600</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 0.8683546781539917, 'eval_accuracy': 0.614, 'eval_runtime': 10.8234, 'eval_samples_per_second': 461.962, 'eval_steps_per_second': 14.506, 'epoch': 1.0}\nEvaluation Metrics: {'eval_loss': 0.7456740140914917, 'eval_accuracy': 0.6818, 'eval_runtime': 10.8562, 'eval_samples_per_second': 460.566, 'eval_steps_per_second': 14.462, 'epoch': 2.0}\nEvaluation Metrics: {'eval_loss': 0.7053418755531311, 'eval_accuracy': 0.7022, 'eval_runtime': 10.8681, 'eval_samples_per_second': 460.064, 'eval_steps_per_second': 14.446, 'epoch': 3.0}\nEvaluation Metrics: {'eval_loss': 0.6897376179695129, 'eval_accuracy': 0.7124, 'eval_runtime': 10.7948, 'eval_samples_per_second': 463.185, 'eval_steps_per_second': 14.544, 'epoch': 4.0}\nEvaluation Metrics: {'eval_loss': 0.6896318197250366, 'eval_accuracy': 0.7116, 'eval_runtime': 10.809, 'eval_samples_per_second': 462.576, 'eval_steps_per_second': 14.525, 'epoch': 5.0}\nSweep Evaluation Accuracy: 0.7116\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▆▆▇▇████</td></tr><tr><td>eval/loss</td><td>██▃▃▂▂▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▄▄▇▇██▁▁▂▂</td></tr><tr><td>eval/samples_per_second</td><td>▅▅▂▂▁▁██▇▇</td></tr><tr><td>eval/steps_per_second</td><td>▅▅▂▂▁▁██▇▇</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>▁▁▁▂▃▃▄▃▅▇▅▇▇▇▅▅▅▅▅▇▅▆▅█▆▅▆█▇█▅▅█▇▆▅▇█▇▆</td></tr><tr><td>train/learning_rate</td><td>▁▃▄▄▅▆▇███▇▇▇▇▇▆▆▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>███▇▇▆▅▄▅▄▄▄▃▄▃▃▂▃▃▃▃▂▃▁▂▃▂▂▂▂▃▁▂▁▂▂▂▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.7116</td></tr><tr><td>eval/loss</td><td>0.68963</td></tr><tr><td>eval/runtime</td><td>10.809</td></tr><tr><td>eval/samples_per_second</td><td>462.576</td></tr><tr><td>eval/steps_per_second</td><td>14.525</td></tr><tr><td>total_flos</td><td>1458820915200000.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>3125</td></tr><tr><td>train/grad_norm</td><td>2.02696</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7559</td></tr><tr><td>train_loss</td><td>0.79171</td></tr><tr><td>train_runtime</td><td>631.9226</td></tr><tr><td>train_samples_per_second</td><td>158.247</td></tr><tr><td>train_steps_per_second</td><td>4.945</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">crisp-sweep-9</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/wssi7orj' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/wssi7orj</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_201716-wssi7orj/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 290mojgh with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.799885161056019e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: constant\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_torch\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_202804-290mojgh</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/290mojgh' target=\"_blank\">skilled-sweep-10</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/290mojgh' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/290mojgh</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 40,875 || all params: 14,392,062 || trainable%: 0.2840\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [390/390 10:16, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.097100</td>\n      <td>1.097554</td>\n      <td>0.350600</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.094800</td>\n      <td>1.095301</td>\n      <td>0.394400</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.082500</td>\n      <td>1.083522</td>\n      <td>0.476800</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.070700</td>\n      <td>1.069302</td>\n      <td>0.478400</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.059300</td>\n      <td>1.056158</td>\n      <td>0.487200</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 1.0975538492202759, 'eval_accuracy': 0.3506, 'eval_runtime': 10.807, 'eval_samples_per_second': 462.663, 'eval_steps_per_second': 14.528, 'epoch': 0.9984}\nEvaluation Metrics: {'eval_loss': 1.095300555229187, 'eval_accuracy': 0.3944, 'eval_runtime': 10.765, 'eval_samples_per_second': 464.468, 'eval_steps_per_second': 14.584, 'epoch': 1.9968}\nEvaluation Metrics: {'eval_loss': 1.0835217237472534, 'eval_accuracy': 0.4768, 'eval_runtime': 10.8086, 'eval_samples_per_second': 462.593, 'eval_steps_per_second': 14.525, 'epoch': 2.9952}\nEvaluation Metrics: {'eval_loss': 1.0693022012710571, 'eval_accuracy': 0.4784, 'eval_runtime': 10.8279, 'eval_samples_per_second': 461.769, 'eval_steps_per_second': 14.5, 'epoch': 3.9936}\nEvaluation Metrics: {'eval_loss': 1.0561578273773193, 'eval_accuracy': 0.4872, 'eval_runtime': 10.788, 'eval_samples_per_second': 463.478, 'eval_steps_per_second': 14.553, 'epoch': 4.992}\nSweep Evaluation Accuracy: 0.4872\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▃▃▇▇████</td></tr><tr><td>eval/loss</td><td>████▆▆▃▃▁▁</td></tr><tr><td>eval/runtime</td><td>▆▆▁▁▆▆██▄▄</td></tr><tr><td>eval/samples_per_second</td><td>▃▃██▃▃▁▁▅▅</td></tr><tr><td>eval/steps_per_second</td><td>▃▃██▃▃▁▁▅▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▄▄▁▅▃▄▆▄▁▁▃▃▆▆▂▁▁▄▂▃▃▄▇▅▅▅▇▇▅▅▇▆▅▅█▇▇▇▇▅</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>████████████▇▇▇▇▇▇▇▇▆▆▆▅▅▅▄▄▃▃▃▃▃▂▂▁▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.4872</td></tr><tr><td>eval/loss</td><td>1.05616</td></tr><tr><td>eval/runtime</td><td>10.788</td></tr><tr><td>eval/samples_per_second</td><td>463.478</td></tr><tr><td>eval/steps_per_second</td><td>14.553</td></tr><tr><td>total_flos</td><td>1444238091878400.0</td></tr><tr><td>train/epoch</td><td>4.992</td></tr><tr><td>train/global_step</td><td>390</td></tr><tr><td>train/grad_norm</td><td>1.62062</td></tr><tr><td>train/learning_rate</td><td>5e-05</td></tr><tr><td>train/loss</td><td>1.0593</td></tr><tr><td>train_loss</td><td>1.08414</td></tr><tr><td>train_runtime</td><td>618.4002</td></tr><tr><td>train_samples_per_second</td><td>161.708</td></tr><tr><td>train_steps_per_second</td><td>0.631</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">skilled-sweep-10</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/290mojgh' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/290mojgh</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_202804-290mojgh/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 05k0437p with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006176083216140577\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: constant\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_8bit\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_203837-05k0437p</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/05k0437p' target=\"_blank\">legendary-sweep-11</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/05k0437p' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/05k0437p</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 160,683 || all params: 14,511,870 || trainable%: 1.1073\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='780' max='780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [780/780 10:37, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.906600</td>\n      <td>0.871383</td>\n      <td>0.629800</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.767800</td>\n      <td>0.745293</td>\n      <td>0.689800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.731800</td>\n      <td>0.685590</td>\n      <td>0.717400</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.657900</td>\n      <td>0.662240</td>\n      <td>0.730600</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 0.871383011341095, 'eval_accuracy': 0.6298, 'eval_runtime': 10.7935, 'eval_samples_per_second': 463.243, 'eval_steps_per_second': 14.546, 'epoch': 0.9984}\nEvaluation Metrics: {'eval_loss': 0.7452929615974426, 'eval_accuracy': 0.6898, 'eval_runtime': 10.9706, 'eval_samples_per_second': 455.763, 'eval_steps_per_second': 14.311, 'epoch': 1.9968}\nEvaluation Metrics: {'eval_loss': 0.6855900287628174, 'eval_accuracy': 0.7174, 'eval_runtime': 10.9338, 'eval_samples_per_second': 457.297, 'eval_steps_per_second': 14.359, 'epoch': 2.9952}\nEvaluation Metrics: {'eval_loss': 0.657213032245636, 'eval_accuracy': 0.7322, 'eval_runtime': 10.8976, 'eval_samples_per_second': 458.817, 'eval_steps_per_second': 14.407, 'epoch': 4.0}\nEvaluation Metrics: {'eval_loss': 0.6622398495674133, 'eval_accuracy': 0.7306, 'eval_runtime': 10.9192, 'eval_samples_per_second': 457.909, 'eval_steps_per_second': 14.378, 'epoch': 4.992}\nSweep Evaluation Accuracy: 0.7306\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▅▅▇▇████</td></tr><tr><td>eval/loss</td><td>██▄▄▂▂▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▁██▇▇▅▅▆▆</td></tr><tr><td>eval/samples_per_second</td><td>██▁▁▂▂▄▄▃▃</td></tr><tr><td>eval/steps_per_second</td><td>██▁▁▂▂▄▄▃▃</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>train/grad_norm</td><td>▁▁▁▁▂▃▂▃▃▃▄▄▄▄▅▄▆▅▇▇▅▆▅▆▆▆▄▅▅▅▆▅▅▄▆▆▇▄▅█</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>████▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▁▂▁▂▃▃▁▁▁▁▁▂▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.7306</td></tr><tr><td>eval/loss</td><td>0.66224</td></tr><tr><td>eval/runtime</td><td>10.9192</td></tr><tr><td>eval/samples_per_second</td><td>457.909</td></tr><tr><td>eval/steps_per_second</td><td>14.378</td></tr><tr><td>total_flos</td><td>1480984221450240.0</td></tr><tr><td>train/epoch</td><td>4.992</td></tr><tr><td>train/global_step</td><td>780</td></tr><tr><td>train/grad_norm</td><td>8.98488</td></tr><tr><td>train/learning_rate</td><td>0.00062</td></tr><tr><td>train/loss</td><td>0.6579</td></tr><tr><td>train_loss</td><td>0.77517</td></tr><tr><td>train_runtime</td><td>637.8298</td></tr><tr><td>train_samples_per_second</td><td>156.782</td></tr><tr><td>train_steps_per_second</td><td>1.223</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">legendary-sweep-11</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/05k0437p' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/05k0437p</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_203837-05k0437p/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xs95t7fx with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.1861392877441224e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: constant\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_8bit\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_204928-xs95t7fx</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/xs95t7fx' target=\"_blank\">eager-sweep-12</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/xs95t7fx' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/xs95t7fx</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 160,683 || all params: 14,511,870 || trainable%: 1.1073\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='1560' max='1560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1560/1560 11:39, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.096800</td>\n      <td>1.097727</td>\n      <td>0.367600</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.088400</td>\n      <td>1.086602</td>\n      <td>0.476400</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.064800</td>\n      <td>1.062975</td>\n      <td>0.484400</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 1.0977267026901245, 'eval_accuracy': 0.3676, 'eval_runtime': 10.9709, 'eval_samples_per_second': 455.75, 'eval_steps_per_second': 14.311, 'epoch': 0.9984}\nEvaluation Metrics: {'eval_loss': 1.095811128616333, 'eval_accuracy': 0.4202, 'eval_runtime': 10.9864, 'eval_samples_per_second': 455.108, 'eval_steps_per_second': 14.29, 'epoch': 2.0}\nEvaluation Metrics: {'eval_loss': 1.0866016149520874, 'eval_accuracy': 0.4764, 'eval_runtime': 10.9233, 'eval_samples_per_second': 457.739, 'eval_steps_per_second': 14.373, 'epoch': 2.9984}\nEvaluation Metrics: {'eval_loss': 1.074446678161621, 'eval_accuracy': 0.4786, 'eval_runtime': 10.8945, 'eval_samples_per_second': 458.946, 'eval_steps_per_second': 14.411, 'epoch': 4.0}\nEvaluation Metrics: {'eval_loss': 1.0629745721817017, 'eval_accuracy': 0.4844, 'eval_runtime': 10.825, 'eval_samples_per_second': 461.894, 'eval_steps_per_second': 14.503, 'epoch': 4.992}\nSweep Evaluation Accuracy: 0.4844\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▄▄██████</td></tr><tr><td>eval/loss</td><td>████▆▆▃▃▁▁</td></tr><tr><td>eval/runtime</td><td>▇▇██▅▅▄▄▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▂▂▁▁▄▄▅▅██</td></tr><tr><td>eval/steps_per_second</td><td>▂▂▁▁▄▄▅▅██</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▁▅▃▃▄▂▅▂▃▄▅▃▃▂▄▄▂▇▇▆▃▅▅▂▂▄▃▃▇█▆▅▄▅▆▄▅▄▃▅</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>███████████▇█▇█▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▄▄▅▄▃▂▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.4844</td></tr><tr><td>eval/loss</td><td>1.06297</td></tr><tr><td>eval/runtime</td><td>10.825</td></tr><tr><td>eval/samples_per_second</td><td>461.894</td></tr><tr><td>eval/steps_per_second</td><td>14.503</td></tr><tr><td>total_flos</td><td>1480984221450240.0</td></tr><tr><td>train/epoch</td><td>4.992</td></tr><tr><td>train/global_step</td><td>1560</td></tr><tr><td>train/grad_norm</td><td>1.24522</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.0648</td></tr><tr><td>train_loss</td><td>1.08676</td></tr><tr><td>train_runtime</td><td>699.8284</td></tr><tr><td>train_samples_per_second</td><td>142.892</td></tr><tr><td>train_steps_per_second</td><td>2.229</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">eager-sweep-12</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/xs95t7fx' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/xs95t7fx</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_204928-xs95t7fx/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eir17vih with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.61698757159985e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: polynomial\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_hf\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_210122-eir17vih</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/eir17vih' target=\"_blank\">dutiful-sweep-13</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/eir17vih' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/eir17vih</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 80,811 || all params: 14,431,998 || trainable%: 0.5599\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [390/390 09:56, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.096500</td>\n      <td>1.097304</td>\n      <td>0.341000</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.092800</td>\n      <td>1.092622</td>\n      <td>0.462600</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.079700</td>\n      <td>1.081043</td>\n      <td>0.478600</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.072800</td>\n      <td>1.073344</td>\n      <td>0.479400</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.071200</td>\n      <td>1.071255</td>\n      <td>0.481800</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 1.097303867340088, 'eval_accuracy': 0.341, 'eval_runtime': 10.881, 'eval_samples_per_second': 459.516, 'eval_steps_per_second': 14.429, 'epoch': 0.9984}\nEvaluation Metrics: {'eval_loss': 1.0926220417022705, 'eval_accuracy': 0.4626, 'eval_runtime': 10.8436, 'eval_samples_per_second': 461.101, 'eval_steps_per_second': 14.479, 'epoch': 1.9968}\nEvaluation Metrics: {'eval_loss': 1.0810425281524658, 'eval_accuracy': 0.4786, 'eval_runtime': 10.8939, 'eval_samples_per_second': 458.972, 'eval_steps_per_second': 14.412, 'epoch': 2.9952}\nEvaluation Metrics: {'eval_loss': 1.0733444690704346, 'eval_accuracy': 0.4794, 'eval_runtime': 10.8053, 'eval_samples_per_second': 462.735, 'eval_steps_per_second': 14.53, 'epoch': 3.9936}\nEvaluation Metrics: {'eval_loss': 1.071255087852478, 'eval_accuracy': 0.4818, 'eval_runtime': 10.829, 'eval_samples_per_second': 461.722, 'eval_steps_per_second': 14.498, 'epoch': 4.992}\nSweep Evaluation Accuracy: 0.4818\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▇▇██████</td></tr><tr><td>eval/loss</td><td>██▇▇▄▄▂▂▁▁</td></tr><tr><td>eval/runtime</td><td>▇▇▄▄██▁▁▃▃</td></tr><tr><td>eval/samples_per_second</td><td>▂▂▅▅▁▁██▆▆</td></tr><tr><td>eval/steps_per_second</td><td>▂▂▅▅▁▁██▆▆</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▅▅▁▆▆▄▄▂▂▄▂▃▃▄█▆▆▃▃▄▃▄▄▄▄▇▇▅▇▄▅▆▆▆▆▄▆▆▅▅</td></tr><tr><td>train/learning_rate</td><td>▄▄███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█████████▇▇▇▇▇▇▇▅▅▆▅▃▃▃▃▃▂▃▃▃▂▂▁▂▂▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.4818</td></tr><tr><td>eval/loss</td><td>1.07126</td></tr><tr><td>eval/runtime</td><td>10.829</td></tr><tr><td>eval/samples_per_second</td><td>461.722</td></tr><tr><td>eval/steps_per_second</td><td>14.498</td></tr><tr><td>total_flos</td><td>1456486801735680.0</td></tr><tr><td>train/epoch</td><td>4.992</td></tr><tr><td>train/global_step</td><td>390</td></tr><tr><td>train/grad_norm</td><td>0.82589</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.0712</td></tr><tr><td>train_loss</td><td>1.08502</td></tr><tr><td>train_runtime</td><td>597.6653</td></tr><tr><td>train_samples_per_second</td><td>167.318</td></tr><tr><td>train_steps_per_second</td><td>0.653</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">dutiful-sweep-13</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/eir17vih' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/eir17vih</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_210122-eir17vih/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: df94yyyx with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.7090420019453033e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: constant_with_warmup\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_8bit\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_211134-df94yyyx</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/df94yyyx' target=\"_blank\">misty-sweep-14</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/df94yyyx' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/df94yyyx</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 80,811 || all params: 14,431,998 || trainable%: 0.5599\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='780' max='780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [780/780 13:44, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.097600</td>\n      <td>1.097991</td>\n      <td>0.373400</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.095700</td>\n      <td>1.096845</td>\n      <td>0.415000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.090900</td>\n      <td>1.092468</td>\n      <td>0.474000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.074000</td>\n      <td>1.073797</td>\n      <td>0.480800</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 1.0979909896850586, 'eval_accuracy': 0.3734, 'eval_runtime': 10.8671, 'eval_samples_per_second': 460.102, 'eval_steps_per_second': 14.447, 'epoch': 0.9984}\nEvaluation Metrics: {'eval_loss': 1.0968449115753174, 'eval_accuracy': 0.415, 'eval_runtime': 10.8202, 'eval_samples_per_second': 462.097, 'eval_steps_per_second': 14.51, 'epoch': 1.9968}\nEvaluation Metrics: {'eval_loss': 1.0924677848815918, 'eval_accuracy': 0.474, 'eval_runtime': 10.8927, 'eval_samples_per_second': 459.023, 'eval_steps_per_second': 14.413, 'epoch': 2.9952}\nEvaluation Metrics: {'eval_loss': 1.0834447145462036, 'eval_accuracy': 0.478, 'eval_runtime': 10.8174, 'eval_samples_per_second': 462.219, 'eval_steps_per_second': 14.514, 'epoch': 4.0}\nEvaluation Metrics: {'eval_loss': 1.0737972259521484, 'eval_accuracy': 0.4808, 'eval_runtime': 10.9231, 'eval_samples_per_second': 457.746, 'eval_steps_per_second': 14.373, 'epoch': 4.992}\nSweep Evaluation Accuracy: 0.4808\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▄▄██████</td></tr><tr><td>eval/loss</td><td>████▆▆▄▄▁▁</td></tr><tr><td>eval/runtime</td><td>▄▄▁▁▆▆▁▁██</td></tr><tr><td>eval/samples_per_second</td><td>▅▅██▃▃██▁▁</td></tr><tr><td>eval/steps_per_second</td><td>▅▅██▃▃██▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▁▅▅▄▄▃▃▃▂▂▄▁▁▇▃▄▃▃▁▁▅▃▃▄▄█▆▄▄▃▃▅▃▅▃▅▅▄▆▇</td></tr><tr><td>train/learning_rate</td><td>▁▃██████████████████████████████████████</td></tr><tr><td>train/loss</td><td>██████████▇▇███▇▇▇▇▇▇▇▇▆▇▆▅▅▅▅▅▅▄▃▂▁▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.4808</td></tr><tr><td>eval/loss</td><td>1.0738</td></tr><tr><td>eval/runtime</td><td>10.9231</td></tr><tr><td>eval/samples_per_second</td><td>457.746</td></tr><tr><td>eval/steps_per_second</td><td>14.373</td></tr><tr><td>total_flos</td><td>1456486801735680.0</td></tr><tr><td>train/epoch</td><td>4.992</td></tr><tr><td>train/global_step</td><td>780</td></tr><tr><td>train/grad_norm</td><td>3.82007</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>1.074</td></tr><tr><td>train_loss</td><td>1.09095</td></tr><tr><td>train_runtime</td><td>825.9824</td></tr><tr><td>train_samples_per_second</td><td>121.068</td></tr><tr><td>train_steps_per_second</td><td>0.944</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">misty-sweep-14</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/df94yyyx' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/df94yyyx</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_211134-df94yyyx/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gfc7295v with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.625710306286862e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: cosine\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_hf\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_212541-gfc7295v</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/gfc7295v' target=\"_blank\">wise-sweep-15</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/gfc7295v' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/gfc7295v</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 40,875 || all params: 14,392,062 || trainable%: 0.2840\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [390/390 11:20, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.098100</td>\n      <td>1.098200</td>\n      <td>0.366400</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.097400</td>\n      <td>1.097843</td>\n      <td>0.361400</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.096100</td>\n      <td>1.097595</td>\n      <td>0.358400</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.095600</td>\n      <td>1.097466</td>\n      <td>0.358800</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.096400</td>\n      <td>1.097448</td>\n      <td>0.358800</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 1.0981999635696411, 'eval_accuracy': 0.3664, 'eval_runtime': 10.9267, 'eval_samples_per_second': 457.595, 'eval_steps_per_second': 14.368, 'epoch': 0.9984}\nEvaluation Metrics: {'eval_loss': 1.0978425741195679, 'eval_accuracy': 0.3614, 'eval_runtime': 10.8571, 'eval_samples_per_second': 460.528, 'eval_steps_per_second': 14.461, 'epoch': 1.9968}\nEvaluation Metrics: {'eval_loss': 1.097594976425171, 'eval_accuracy': 0.3584, 'eval_runtime': 10.7958, 'eval_samples_per_second': 463.144, 'eval_steps_per_second': 14.543, 'epoch': 2.9952}\nEvaluation Metrics: {'eval_loss': 1.097465991973877, 'eval_accuracy': 0.3588, 'eval_runtime': 10.875, 'eval_samples_per_second': 459.769, 'eval_steps_per_second': 14.437, 'epoch': 3.9936}\nEvaluation Metrics: {'eval_loss': 1.0974476337432861, 'eval_accuracy': 0.3588, 'eval_runtime': 10.8945, 'eval_samples_per_second': 458.947, 'eval_steps_per_second': 14.411, 'epoch': 4.992}\nSweep Evaluation Accuracy: 0.3588\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>██▄▄▁▁▁▁▁▁</td></tr><tr><td>eval/loss</td><td>██▅▅▂▂▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>██▄▄▁▁▅▅▆▆</td></tr><tr><td>eval/samples_per_second</td><td>▁▁▅▅██▄▄▃▃</td></tr><tr><td>eval/steps_per_second</td><td>▁▁▅▅██▄▄▃▃</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▄▄▁▁▂▅▅▃▃▄▅▅▅▂▂▂▂▃█▃▄▄▂▂▃▃▆▆▃▃▁▁▄▃▁▆▆▂▄▂</td></tr><tr><td>train/learning_rate</td><td>▅████████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█████▇▇▇▆▇▅▅▅▆▄▅▅▅▅▄▆▄▃▄▂▂▂▂▆▅▁▃▃▂▂▄▄▄▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.3588</td></tr><tr><td>eval/loss</td><td>1.09745</td></tr><tr><td>eval/runtime</td><td>10.8945</td></tr><tr><td>eval/samples_per_second</td><td>458.947</td></tr><tr><td>eval/steps_per_second</td><td>14.411</td></tr><tr><td>total_flos</td><td>1444238091878400.0</td></tr><tr><td>train/epoch</td><td>4.992</td></tr><tr><td>train/global_step</td><td>390</td></tr><tr><td>train/grad_norm</td><td>1.26833</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>1.0964</td></tr><tr><td>train_loss</td><td>1.0971</td></tr><tr><td>train_runtime</td><td>682.598</td></tr><tr><td>train_samples_per_second</td><td>146.499</td></tr><tr><td>train_steps_per_second</td><td>0.571</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">wise-sweep-15</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/gfc7295v' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/gfc7295v</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_212541-gfc7295v/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dp600hbr with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.7911795257224173e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: constant\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_hf\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_213720-dp600hbr</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/dp600hbr' target=\"_blank\">azure-sweep-16</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/dp600hbr' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/dp600hbr</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 80,811 || all params: 14,431,998 || trainable%: 0.5599\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='1560' max='1560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1560/1560 13:54, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.094300</td>\n      <td>1.093883</td>\n      <td>0.466400</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.052500</td>\n      <td>1.042910</td>\n      <td>0.505400</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.006100</td>\n      <td>0.995829</td>\n      <td>0.534000</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 1.0938830375671387, 'eval_accuracy': 0.4664, 'eval_runtime': 10.9541, 'eval_samples_per_second': 456.45, 'eval_steps_per_second': 14.333, 'epoch': 0.9984}\nEvaluation Metrics: {'eval_loss': 1.0680770874023438, 'eval_accuracy': 0.484, 'eval_runtime': 10.9367, 'eval_samples_per_second': 457.178, 'eval_steps_per_second': 14.355, 'epoch': 2.0}\nEvaluation Metrics: {'eval_loss': 1.0429096221923828, 'eval_accuracy': 0.5054, 'eval_runtime': 10.8473, 'eval_samples_per_second': 460.942, 'eval_steps_per_second': 14.474, 'epoch': 2.9984}\nEvaluation Metrics: {'eval_loss': 1.0184144973754883, 'eval_accuracy': 0.5228, 'eval_runtime': 10.85, 'eval_samples_per_second': 460.83, 'eval_steps_per_second': 14.47, 'epoch': 4.0}\nEvaluation Metrics: {'eval_loss': 0.9958286881446838, 'eval_accuracy': 0.534, 'eval_runtime': 10.9559, 'eval_samples_per_second': 456.377, 'eval_steps_per_second': 14.33, 'epoch': 4.992}\nSweep Evaluation Accuracy: 0.5340\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▃▃▅▅▇▇██</td></tr><tr><td>eval/loss</td><td>██▆▆▄▄▃▃▁▁</td></tr><tr><td>eval/runtime</td><td>██▇▇▁▁▁▁██</td></tr><tr><td>eval/samples_per_second</td><td>▁▁▂▂████▁▁</td></tr><tr><td>eval/steps_per_second</td><td>▁▁▂▂████▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▃▁▁▅▅▄▂▃▄▅▃▃▃▃▃▄▃▄▄▃▄▄▆▅▅▇▆▆▅▄▅▆▇▆▇▇▆▇█</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█████████████▇▇▆▆▆▆▅▅▄▅▄▄▄▃▄▄▃▃▂▃▃▂▂▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.534</td></tr><tr><td>eval/loss</td><td>0.99583</td></tr><tr><td>eval/runtime</td><td>10.9559</td></tr><tr><td>eval/samples_per_second</td><td>456.377</td></tr><tr><td>eval/steps_per_second</td><td>14.33</td></tr><tr><td>total_flos</td><td>1456486801735680.0</td></tr><tr><td>train/epoch</td><td>4.992</td></tr><tr><td>train/global_step</td><td>1560</td></tr><tr><td>train/grad_norm</td><td>5.50354</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>1.0061</td></tr><tr><td>train_loss</td><td>1.0554</td></tr><tr><td>train_runtime</td><td>834.6867</td></tr><tr><td>train_samples_per_second</td><td>119.805</td></tr><tr><td>train_steps_per_second</td><td>1.869</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">azure-sweep-16</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/dp600hbr' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/dp600hbr</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_213720-dp600hbr/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0xa0h7p2 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.2629802841396012e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: constant_with_warmup\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_hf\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_215127-0xa0h7p2</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/0xa0h7p2' target=\"_blank\">different-sweep-17</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/0xa0h7p2' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/0xa0h7p2</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 40,875 || all params: 14,392,062 || trainable%: 0.2840\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6250/6250 14:22, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.097400</td>\n      <td>1.097273</td>\n      <td>0.361200</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.090400</td>\n      <td>1.088341</td>\n      <td>0.479600</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.062900</td>\n      <td>1.063406</td>\n      <td>0.478800</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.051100</td>\n      <td>1.042836</td>\n      <td>0.486000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.049700</td>\n      <td>1.024445</td>\n      <td>0.497400</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 1.0972734689712524, 'eval_accuracy': 0.3612, 'eval_runtime': 10.9218, 'eval_samples_per_second': 457.8, 'eval_steps_per_second': 14.375, 'epoch': 1.0}\nEvaluation Metrics: {'eval_loss': 1.088341236114502, 'eval_accuracy': 0.4796, 'eval_runtime': 10.8741, 'eval_samples_per_second': 459.808, 'eval_steps_per_second': 14.438, 'epoch': 2.0}\nEvaluation Metrics: {'eval_loss': 1.0634055137634277, 'eval_accuracy': 0.4788, 'eval_runtime': 10.8301, 'eval_samples_per_second': 461.677, 'eval_steps_per_second': 14.497, 'epoch': 3.0}\nEvaluation Metrics: {'eval_loss': 1.0428359508514404, 'eval_accuracy': 0.486, 'eval_runtime': 10.8728, 'eval_samples_per_second': 459.865, 'eval_steps_per_second': 14.44, 'epoch': 4.0}\nEvaluation Metrics: {'eval_loss': 1.0244454145431519, 'eval_accuracy': 0.4974, 'eval_runtime': 10.8316, 'eval_samples_per_second': 461.61, 'eval_steps_per_second': 14.495, 'epoch': 5.0}\nSweep Evaluation Accuracy: 0.4974\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▇▇▇▇▇▇██</td></tr><tr><td>eval/loss</td><td>██▇▇▅▅▃▃▁▁</td></tr><tr><td>eval/runtime</td><td>██▄▄▁▁▄▄▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▁▅▅██▅▅██</td></tr><tr><td>eval/steps_per_second</td><td>▁▁▅▅██▅▅██</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>▂▅▅▁▃▃▆▅▃▁▆▁▇▂▂▄█▆▅▃▃▄▂▃▄▂▄▄▆▅▇▅▄▇▆▆▆▆▇▅</td></tr><tr><td>train/learning_rate</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/loss</td><td>██████████▇▇███▇▇▇▇▇▆▆▆▆▇▆▅▅▅▆▄▄▃▅▄▁▂▅▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.4974</td></tr><tr><td>eval/loss</td><td>1.02445</td></tr><tr><td>eval/runtime</td><td>10.8316</td></tr><tr><td>eval/samples_per_second</td><td>461.61</td></tr><tr><td>eval/steps_per_second</td><td>14.495</td></tr><tr><td>total_flos</td><td>1446552576000000.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>6250</td></tr><tr><td>train/grad_norm</td><td>2.2361</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.0497</td></tr><tr><td>train_loss</td><td>1.07098</td></tr><tr><td>train_runtime</td><td>862.3886</td></tr><tr><td>train_samples_per_second</td><td>115.957</td></tr><tr><td>train_steps_per_second</td><td>7.247</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">different-sweep-17</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/0xa0h7p2' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/0xa0h7p2</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_215127-0xa0h7p2/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y0n83ib3 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002781118528691012\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: cosine_with_restarts\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adafactor\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_220606-y0n83ib3</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/y0n83ib3' target=\"_blank\">avid-sweep-18</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/y0n83ib3' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/y0n83ib3</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 160,683 || all params: 14,511,870 || trainable%: 1.1073\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [390/390 10:15, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.074300</td>\n      <td>1.062466</td>\n      <td>0.479200</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.004900</td>\n      <td>0.991924</td>\n      <td>0.535800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.952300</td>\n      <td>0.948297</td>\n      <td>0.566600</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.934600</td>\n      <td>0.931988</td>\n      <td>0.586200</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.950100</td>\n      <td>0.932678</td>\n      <td>0.582200</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 1.0624656677246094, 'eval_accuracy': 0.4792, 'eval_runtime': 10.9491, 'eval_samples_per_second': 456.66, 'eval_steps_per_second': 14.339, 'epoch': 0.9984}\nEvaluation Metrics: {'eval_loss': 0.9919240474700928, 'eval_accuracy': 0.5358, 'eval_runtime': 10.9503, 'eval_samples_per_second': 456.609, 'eval_steps_per_second': 14.338, 'epoch': 1.9968}\nEvaluation Metrics: {'eval_loss': 0.9482971429824829, 'eval_accuracy': 0.5666, 'eval_runtime': 10.9509, 'eval_samples_per_second': 456.584, 'eval_steps_per_second': 14.337, 'epoch': 2.9952}\nEvaluation Metrics: {'eval_loss': 0.9319877028465271, 'eval_accuracy': 0.5862, 'eval_runtime': 10.9039, 'eval_samples_per_second': 458.55, 'eval_steps_per_second': 14.398, 'epoch': 3.9936}\nEvaluation Metrics: {'eval_loss': 0.9326784014701843, 'eval_accuracy': 0.5822, 'eval_runtime': 10.9174, 'eval_samples_per_second': 457.987, 'eval_steps_per_second': 14.381, 'epoch': 4.992}\nSweep Evaluation Accuracy: 0.5822\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▅▅▇▇████</td></tr><tr><td>eval/loss</td><td>██▄▄▂▂▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>██████▁▁▃▃</td></tr><tr><td>eval/samples_per_second</td><td>▁▁▁▁▁▁██▆▆</td></tr><tr><td>eval/steps_per_second</td><td>▁▁▁▁▁▁██▆▆</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▃▃▁▂▃▃▄▄▄▄▅▄▄▄▅▆▆▄▄▄▆▆▅▅▅▅▅▅██▇▇▆▆▇▆▇▆█▆</td></tr><tr><td>train/learning_rate</td><td>██████▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>███████▇▇▆▆▅▅▅▄▄▄▄▄▃▂▂▃▃▂▂▂▁▁▂▁▁▁▁▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.5822</td></tr><tr><td>eval/loss</td><td>0.93268</td></tr><tr><td>eval/runtime</td><td>10.9174</td></tr><tr><td>eval/samples_per_second</td><td>457.987</td></tr><tr><td>eval/steps_per_second</td><td>14.381</td></tr><tr><td>total_flos</td><td>1480984221450240.0</td></tr><tr><td>train/epoch</td><td>4.992</td></tr><tr><td>train/global_step</td><td>390</td></tr><tr><td>train/grad_norm</td><td>1.44192</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>0.9501</td></tr><tr><td>train_loss</td><td>0.99406</td></tr><tr><td>train_runtime</td><td>617.2675</td></tr><tr><td>train_samples_per_second</td><td>162.004</td></tr><tr><td>train_steps_per_second</td><td>0.632</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">avid-sweep-18</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/y0n83ib3' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/y0n83ib3</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_220606-y0n83ib3/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sow0axxu with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004438363192903519\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: linear\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_8bit\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_221638-sow0axxu</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/sow0axxu' target=\"_blank\">fluent-sweep-19</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/sow0axxu' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/sow0axxu</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 80,811 || all params: 14,431,998 || trainable%: 0.5599\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6250/6250 14:24, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.796400</td>\n      <td>0.736703</td>\n      <td>0.695800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.741800</td>\n      <td>0.668333</td>\n      <td>0.729000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.658200</td>\n      <td>0.656741</td>\n      <td>0.733000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.595300</td>\n      <td>0.638280</td>\n      <td>0.741200</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.622100</td>\n      <td>0.639986</td>\n      <td>0.740800</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 0.736702561378479, 'eval_accuracy': 0.6958, 'eval_runtime': 10.9726, 'eval_samples_per_second': 455.68, 'eval_steps_per_second': 14.308, 'epoch': 1.0}\nEvaluation Metrics: {'eval_loss': 0.6683334112167358, 'eval_accuracy': 0.729, 'eval_runtime': 10.9243, 'eval_samples_per_second': 457.696, 'eval_steps_per_second': 14.372, 'epoch': 2.0}\nEvaluation Metrics: {'eval_loss': 0.6567407250404358, 'eval_accuracy': 0.733, 'eval_runtime': 10.878, 'eval_samples_per_second': 459.643, 'eval_steps_per_second': 14.433, 'epoch': 3.0}\nEvaluation Metrics: {'eval_loss': 0.6382800936698914, 'eval_accuracy': 0.7412, 'eval_runtime': 10.891, 'eval_samples_per_second': 459.095, 'eval_steps_per_second': 14.416, 'epoch': 4.0}\nEvaluation Metrics: {'eval_loss': 0.6399861574172974, 'eval_accuracy': 0.7408, 'eval_runtime': 10.855, 'eval_samples_per_second': 460.617, 'eval_steps_per_second': 14.463, 'epoch': 5.0}\nSweep Evaluation Accuracy: 0.7408\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▆▆▇▇████</td></tr><tr><td>eval/loss</td><td>██▃▃▂▂▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>██▅▅▂▂▃▃▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▁▄▄▇▇▆▆██</td></tr><tr><td>eval/steps_per_second</td><td>▁▁▄▄▇▇▆▆██</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▁▃▂▂▂▄▅▃▃▂▃▃▄▆▄▃▅▅▅▄▃▅▅▅▆▅▆▄▆▇▄▄▆█▅▄▅▆▄▆</td></tr><tr><td>train/learning_rate</td><td>██████▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>███▆▆▆▆▄▅▃▄▄▄▃▅▄▄▅▃▃▂▂▂▃▃▂▂▄▂▂▂▃▂▄▂▁▁▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.7408</td></tr><tr><td>eval/loss</td><td>0.63999</td></tr><tr><td>eval/runtime</td><td>10.855</td></tr><tr><td>eval/samples_per_second</td><td>460.617</td></tr><tr><td>eval/steps_per_second</td><td>14.463</td></tr><tr><td>total_flos</td><td>1458820915200000.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>6250</td></tr><tr><td>train/grad_norm</td><td>8.47301</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6221</td></tr><tr><td>train_loss</td><td>0.70305</td></tr><tr><td>train_runtime</td><td>864.6388</td></tr><tr><td>train_samples_per_second</td><td>115.655</td></tr><tr><td>train_steps_per_second</td><td>7.228</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">fluent-sweep-19</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/sow0axxu' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/sow0axxu</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_221638-sow0axxu/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uhifpseh with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5.525194448670556e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: constant\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_8bit\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_223116-uhifpseh</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/uhifpseh' target=\"_blank\">misunderstood-sweep-20</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/uhifpseh' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/uhifpseh</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 160,683 || all params: 14,511,870 || trainable%: 1.1073\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3125/3125 14:17, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.057000</td>\n      <td>1.048120</td>\n      <td>0.492000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.998500</td>\n      <td>0.973045</td>\n      <td>0.547600</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.946900</td>\n      <td>0.939146</td>\n      <td>0.559400</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.921900</td>\n      <td>0.889335</td>\n      <td>0.597200</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.871400</td>\n      <td>0.853230</td>\n      <td>0.628200</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 1.0481200218200684, 'eval_accuracy': 0.492, 'eval_runtime': 10.9071, 'eval_samples_per_second': 458.418, 'eval_steps_per_second': 14.394, 'epoch': 1.0}\nEvaluation Metrics: {'eval_loss': 0.9730445146560669, 'eval_accuracy': 0.5476, 'eval_runtime': 10.957, 'eval_samples_per_second': 456.329, 'eval_steps_per_second': 14.329, 'epoch': 2.0}\nEvaluation Metrics: {'eval_loss': 0.9391456842422485, 'eval_accuracy': 0.5594, 'eval_runtime': 11.0108, 'eval_samples_per_second': 454.099, 'eval_steps_per_second': 14.259, 'epoch': 3.0}\nEvaluation Metrics: {'eval_loss': 0.8893353343009949, 'eval_accuracy': 0.5972, 'eval_runtime': 10.8923, 'eval_samples_per_second': 459.041, 'eval_steps_per_second': 14.414, 'epoch': 4.0}\nEvaluation Metrics: {'eval_loss': 0.8532300591468811, 'eval_accuracy': 0.6282, 'eval_runtime': 10.8921, 'eval_samples_per_second': 459.049, 'eval_steps_per_second': 14.414, 'epoch': 5.0}\nSweep Evaluation Accuracy: 0.6282\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▄▄▄▄▆▆██</td></tr><tr><td>eval/loss</td><td>██▅▅▄▄▂▂▁▁</td></tr><tr><td>eval/runtime</td><td>▂▂▅▅██▁▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▇▇▄▄▁▁████</td></tr><tr><td>eval/steps_per_second</td><td>▇▇▄▄▁▁████</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇█</td></tr><tr><td>train/grad_norm</td><td>▁▂▁▁▁▂▂▂▃▂▂▂▃▂▃▂▄▅▅▃▅▃▄▃▄▇▅▄▃▇▆▅▅▆▇█▆▅▅▅</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█████▇▇▆▆▆▆▆▅▆▆▆▄▅▄▄▃▄▄▃▃▃▃▃▃▄▃▄▃▂▁▂▂▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.6282</td></tr><tr><td>eval/loss</td><td>0.85323</td></tr><tr><td>eval/runtime</td><td>10.8921</td></tr><tr><td>eval/samples_per_second</td><td>459.049</td></tr><tr><td>eval/steps_per_second</td><td>14.414</td></tr><tr><td>total_flos</td><td>1483357593600000.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>3125</td></tr><tr><td>train/grad_norm</td><td>5.11056</td></tr><tr><td>train/learning_rate</td><td>6e-05</td></tr><tr><td>train/loss</td><td>0.8714</td></tr><tr><td>train_loss</td><td>0.97177</td></tr><tr><td>train_runtime</td><td>857.555</td></tr><tr><td>train_samples_per_second</td><td>116.611</td></tr><tr><td>train_steps_per_second</td><td>3.644</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">misunderstood-sweep-20</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/uhifpseh' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/uhifpseh</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_223116-uhifpseh/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3resivq7 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002708390624659358\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: cosine\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_8bit\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_224548-3resivq7</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/3resivq7' target=\"_blank\">honest-sweep-21</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/3resivq7' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/3resivq7</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 80,811 || all params: 14,431,998 || trainable%: 0.5599\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='95' max='95' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [95/95 09:46, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.098300</td>\n      <td>1.097671</td>\n      <td>0.337800</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.095700</td>\n      <td>1.094693</td>\n      <td>0.398800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.090500</td>\n      <td>1.086113</td>\n      <td>0.481200</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.082100</td>\n      <td>1.080993</td>\n      <td>0.481000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.078700</td>\n      <td>1.080300</td>\n      <td>0.480600</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 1.097670555114746, 'eval_accuracy': 0.3378, 'eval_runtime': 10.8839, 'eval_samples_per_second': 459.395, 'eval_steps_per_second': 14.425, 'epoch': 0.9728}\nEvaluation Metrics: {'eval_loss': 1.0946928262710571, 'eval_accuracy': 0.3988, 'eval_runtime': 10.9147, 'eval_samples_per_second': 458.099, 'eval_steps_per_second': 14.384, 'epoch': 1.9968}\nEvaluation Metrics: {'eval_loss': 1.08611261844635, 'eval_accuracy': 0.4812, 'eval_runtime': 10.9183, 'eval_samples_per_second': 457.947, 'eval_steps_per_second': 14.38, 'epoch': 2.9696}\nEvaluation Metrics: {'eval_loss': 1.0809928178787231, 'eval_accuracy': 0.481, 'eval_runtime': 10.8943, 'eval_samples_per_second': 458.956, 'eval_steps_per_second': 14.411, 'epoch': 3.9936}\nEvaluation Metrics: {'eval_loss': 1.0802998542785645, 'eval_accuracy': 0.4806, 'eval_runtime': 10.9724, 'eval_samples_per_second': 455.689, 'eval_steps_per_second': 14.309, 'epoch': 4.864}\nSweep Evaluation Accuracy: 0.4806\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▄▄██████</td></tr><tr><td>eval/loss</td><td>██▇▇▃▃▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▁▃▃▄▄▂▂██</td></tr><tr><td>eval/samples_per_second</td><td>██▆▆▅▅▇▇▁▁</td></tr><tr><td>eval/steps_per_second</td><td>██▆▆▅▅▇▇▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▄▄▅▅▅▅▆▆▇▇▇▇██████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▄▄▅▅▅▅▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▂▂▄▄▁▁▂▂▇▇▆▆▆▆██▆▆</td></tr><tr><td>train/learning_rate</td><td>▆▆██▇▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>████▇▇▆▆▅▅▃▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.4806</td></tr><tr><td>eval/loss</td><td>1.0803</td></tr><tr><td>eval/runtime</td><td>10.9724</td></tr><tr><td>eval/samples_per_second</td><td>455.689</td></tr><tr><td>eval/steps_per_second</td><td>14.309</td></tr><tr><td>total_flos</td><td>1419140986306560.0</td></tr><tr><td>train/epoch</td><td>4.864</td></tr><tr><td>train/global_step</td><td>95</td></tr><tr><td>train/grad_norm</td><td>2.43516</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.0787</td></tr><tr><td>train_loss</td><td>1.0886</td></tr><tr><td>train_runtime</td><td>592.6062</td></tr><tr><td>train_samples_per_second</td><td>168.746</td></tr><tr><td>train_steps_per_second</td><td>0.16</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">honest-sweep-21</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/3resivq7' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/3resivq7</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_224548-3resivq7/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: joix463a with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007158746505068307\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: linear\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_8bit\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_225554-joix463a</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/joix463a' target=\"_blank\">daily-sweep-22</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/joix463a' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/joix463a</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 160,683 || all params: 14,511,870 || trainable%: 1.1073\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='780' max='780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [780/780 11:38, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.941100</td>\n      <td>0.938707</td>\n      <td>0.561000</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.793800</td>\n      <td>0.778376</td>\n      <td>0.673000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.761600</td>\n      <td>0.721162</td>\n      <td>0.704000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.709200</td>\n      <td>0.702326</td>\n      <td>0.710800</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 0.9387072324752808, 'eval_accuracy': 0.561, 'eval_runtime': 10.9379, 'eval_samples_per_second': 457.127, 'eval_steps_per_second': 14.354, 'epoch': 0.9984}\nEvaluation Metrics: {'eval_loss': 0.7783761620521545, 'eval_accuracy': 0.673, 'eval_runtime': 10.9549, 'eval_samples_per_second': 456.416, 'eval_steps_per_second': 14.331, 'epoch': 1.9968}\nEvaluation Metrics: {'eval_loss': 0.7211621999740601, 'eval_accuracy': 0.704, 'eval_runtime': 10.9536, 'eval_samples_per_second': 456.47, 'eval_steps_per_second': 14.333, 'epoch': 2.9952}\nEvaluation Metrics: {'eval_loss': 0.714576005935669, 'eval_accuracy': 0.7046, 'eval_runtime': 11.0193, 'eval_samples_per_second': 453.749, 'eval_steps_per_second': 14.248, 'epoch': 4.0}\nEvaluation Metrics: {'eval_loss': 0.7023257613182068, 'eval_accuracy': 0.7108, 'eval_runtime': 10.9496, 'eval_samples_per_second': 456.638, 'eval_steps_per_second': 14.338, 'epoch': 4.992}\nSweep Evaluation Accuracy: 0.7108\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▆▆██████</td></tr><tr><td>eval/loss</td><td>██▃▃▂▂▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▁▂▂▂▂██▂▂</td></tr><tr><td>eval/samples_per_second</td><td>██▇▇▇▇▁▁▇▇</td></tr><tr><td>eval/steps_per_second</td><td>██▆▆▇▇▁▁▇▇</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▂▂▂▁▂▂▅▃▃▂▃▄▄▄▄▄▃▄▆▆▅▅▅▅▇▆▄▄▆▆█▅▆▄▆▇▅▆▄▆</td></tr><tr><td>train/learning_rate</td><td>▂▂▃▄▄██▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁</td></tr><tr><td>train/loss</td><td>███▇▆▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▁▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.7108</td></tr><tr><td>eval/loss</td><td>0.70233</td></tr><tr><td>eval/runtime</td><td>10.9496</td></tr><tr><td>eval/samples_per_second</td><td>456.638</td></tr><tr><td>eval/steps_per_second</td><td>14.338</td></tr><tr><td>total_flos</td><td>1480984221450240.0</td></tr><tr><td>train/epoch</td><td>4.992</td></tr><tr><td>train/global_step</td><td>780</td></tr><tr><td>train/grad_norm</td><td>5.85772</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7092</td></tr><tr><td>train_loss</td><td>0.82138</td></tr><tr><td>train_runtime</td><td>699.5447</td></tr><tr><td>train_samples_per_second</td><td>142.95</td></tr><tr><td>train_steps_per_second</td><td>1.115</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">daily-sweep-22</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/joix463a' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/joix463a</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_225554-joix463a/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jfyl2cm0 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5.466854411236187e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: constant\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_8bit\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_230747-jfyl2cm0</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/jfyl2cm0' target=\"_blank\">gentle-sweep-23</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/jfyl2cm0' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/jfyl2cm0</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 40,875 || all params: 14,392,062 || trainable%: 0.2840\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='95' max='95' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [95/95 09:46, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.098300</td>\n      <td>1.098203</td>\n      <td>0.358400</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.097600</td>\n      <td>1.097858</td>\n      <td>0.348400</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.096900</td>\n      <td>1.097540</td>\n      <td>0.338000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.095800</td>\n      <td>1.097069</td>\n      <td>0.339600</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.094800</td>\n      <td>1.096376</td>\n      <td>0.361000</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 1.0982027053833008, 'eval_accuracy': 0.3584, 'eval_runtime': 10.8763, 'eval_samples_per_second': 459.713, 'eval_steps_per_second': 14.435, 'epoch': 0.9728}\nEvaluation Metrics: {'eval_loss': 1.097858190536499, 'eval_accuracy': 0.3484, 'eval_runtime': 10.8825, 'eval_samples_per_second': 459.452, 'eval_steps_per_second': 14.427, 'epoch': 1.9968}\nEvaluation Metrics: {'eval_loss': 1.097540020942688, 'eval_accuracy': 0.338, 'eval_runtime': 10.9135, 'eval_samples_per_second': 458.148, 'eval_steps_per_second': 14.386, 'epoch': 2.9696}\nEvaluation Metrics: {'eval_loss': 1.0970693826675415, 'eval_accuracy': 0.3396, 'eval_runtime': 10.9214, 'eval_samples_per_second': 457.818, 'eval_steps_per_second': 14.375, 'epoch': 3.9936}\nEvaluation Metrics: {'eval_loss': 1.096375823020935, 'eval_accuracy': 0.361, 'eval_runtime': 11.0482, 'eval_samples_per_second': 452.561, 'eval_steps_per_second': 14.21, 'epoch': 4.864}\nSweep Evaluation Accuracy: 0.3610\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▇▇▄▄▁▁▁▁██</td></tr><tr><td>eval/loss</td><td>██▇▇▅▅▄▄▁▁</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▃▃▃▃██</td></tr><tr><td>eval/samples_per_second</td><td>████▆▆▆▆▁▁</td></tr><tr><td>eval/steps_per_second</td><td>████▆▆▆▆▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▄▄▅▅▅▅▆▆▇▇▇▇██████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▄▄▅▅▅▅▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▄▄▆▆▂▂▃▃▆▆▆▆▁▁██▆▆</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>██▇▇▇▇▆▆▅▅▃▃▃▃▃▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.361</td></tr><tr><td>eval/loss</td><td>1.09638</td></tr><tr><td>eval/runtime</td><td>11.0482</td></tr><tr><td>eval/samples_per_second</td><td>452.561</td></tr><tr><td>eval/steps_per_second</td><td>14.21</td></tr><tr><td>total_flos</td><td>1407206345932800.0</td></tr><tr><td>train/epoch</td><td>4.864</td></tr><tr><td>train/global_step</td><td>95</td></tr><tr><td>train/grad_norm</td><td>1.67935</td></tr><tr><td>train/learning_rate</td><td>5e-05</td></tr><tr><td>train/loss</td><td>1.0948</td></tr><tr><td>train_loss</td><td>1.09665</td></tr><tr><td>train_runtime</td><td>592.2421</td></tr><tr><td>train_samples_per_second</td><td>168.85</td></tr><tr><td>train_steps_per_second</td><td>0.16</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">gentle-sweep-23</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/jfyl2cm0' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/jfyl2cm0</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_230747-jfyl2cm0/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 417hib91 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003657371211368039\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: constant_with_warmup\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_torch\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_231753-417hib91</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/417hib91' target=\"_blank\">firm-sweep-24</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/417hib91' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/417hib91</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 40,875 || all params: 14,392,062 || trainable%: 0.2840\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='1560' max='1560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1560/1560 11:32, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.980100</td>\n      <td>0.969488</td>\n      <td>0.534000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.794700</td>\n      <td>0.807192</td>\n      <td>0.653800</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.734000</td>\n      <td>0.706591</td>\n      <td>0.706000</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 0.9694877862930298, 'eval_accuracy': 0.534, 'eval_runtime': 10.8956, 'eval_samples_per_second': 458.902, 'eval_steps_per_second': 14.41, 'epoch': 0.9984}\nEvaluation Metrics: {'eval_loss': 0.8495268821716309, 'eval_accuracy': 0.6406, 'eval_runtime': 10.9037, 'eval_samples_per_second': 458.559, 'eval_steps_per_second': 14.399, 'epoch': 2.0}\nEvaluation Metrics: {'eval_loss': 0.8071922659873962, 'eval_accuracy': 0.6538, 'eval_runtime': 10.8801, 'eval_samples_per_second': 459.554, 'eval_steps_per_second': 14.43, 'epoch': 2.9984}\nEvaluation Metrics: {'eval_loss': 0.7372356653213501, 'eval_accuracy': 0.6868, 'eval_runtime': 10.8731, 'eval_samples_per_second': 459.849, 'eval_steps_per_second': 14.439, 'epoch': 4.0}\nEvaluation Metrics: {'eval_loss': 0.7065905332565308, 'eval_accuracy': 0.706, 'eval_runtime': 10.9332, 'eval_samples_per_second': 457.322, 'eval_steps_per_second': 14.36, 'epoch': 4.992}\nSweep Evaluation Accuracy: 0.7060\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▅▅▆▆▇▇██</td></tr><tr><td>eval/loss</td><td>██▅▅▄▄▂▂▁▁</td></tr><tr><td>eval/runtime</td><td>▄▄▅▅▂▂▁▁██</td></tr><tr><td>eval/samples_per_second</td><td>▅▅▄▄▇▇██▁▁</td></tr><tr><td>eval/steps_per_second</td><td>▅▅▄▄▇▇██▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▁▁▁▁▁▂▂▂▂▅▃▅▄▃▄▄▃▄▄▄▅▅▅█▆▄▄▄▄▅▅▅▅▆█▅▅▆▆▆</td></tr><tr><td>train/learning_rate</td><td>▁▄▄▅▅▆▆▆████████████████████████████████</td></tr><tr><td>train/loss</td><td>█████▇▇▇▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▃▂▂▃▂▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.706</td></tr><tr><td>eval/loss</td><td>0.70659</td></tr><tr><td>eval/runtime</td><td>10.9332</td></tr><tr><td>eval/samples_per_second</td><td>457.322</td></tr><tr><td>eval/steps_per_second</td><td>14.36</td></tr><tr><td>total_flos</td><td>1444238091878400.0</td></tr><tr><td>train/epoch</td><td>4.992</td></tr><tr><td>train/global_step</td><td>1560</td></tr><tr><td>train/grad_norm</td><td>15.0216</td></tr><tr><td>train/learning_rate</td><td>0.00037</td></tr><tr><td>train/loss</td><td>0.734</td></tr><tr><td>train_loss</td><td>0.85997</td></tr><tr><td>train_runtime</td><td>693.252</td></tr><tr><td>train_samples_per_second</td><td>144.248</td></tr><tr><td>train_steps_per_second</td><td>2.25</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">firm-sweep-24</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/417hib91' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/417hib91</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_231753-417hib91/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p9ysimmd with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.22001078772142e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: polynomial\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adafactor\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_232942-p9ysimmd</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/p9ysimmd' target=\"_blank\">feasible-sweep-25</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/p9ysimmd' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/p9ysimmd</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 80,811 || all params: 14,431,998 || trainable%: 0.5599\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3125/3125 11:44, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.037600</td>\n      <td>1.022918</td>\n      <td>0.515800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.980100</td>\n      <td>0.957147</td>\n      <td>0.557800</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.942100</td>\n      <td>0.929627</td>\n      <td>0.565800</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.945900</td>\n      <td>0.913083</td>\n      <td>0.579400</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.914000</td>\n      <td>0.906540</td>\n      <td>0.585800</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 1.0229183435440063, 'eval_accuracy': 0.5158, 'eval_runtime': 11.0677, 'eval_samples_per_second': 451.765, 'eval_steps_per_second': 14.185, 'epoch': 1.0}\nEvaluation Metrics: {'eval_loss': 0.9571465849876404, 'eval_accuracy': 0.5578, 'eval_runtime': 10.9006, 'eval_samples_per_second': 458.69, 'eval_steps_per_second': 14.403, 'epoch': 2.0}\nEvaluation Metrics: {'eval_loss': 0.9296265840530396, 'eval_accuracy': 0.5658, 'eval_runtime': 10.9172, 'eval_samples_per_second': 457.991, 'eval_steps_per_second': 14.381, 'epoch': 3.0}\nEvaluation Metrics: {'eval_loss': 0.9130834937095642, 'eval_accuracy': 0.5794, 'eval_runtime': 11.0065, 'eval_samples_per_second': 454.279, 'eval_steps_per_second': 14.264, 'epoch': 4.0}\nEvaluation Metrics: {'eval_loss': 0.9065399169921875, 'eval_accuracy': 0.5858, 'eval_runtime': 11.0159, 'eval_samples_per_second': 453.889, 'eval_steps_per_second': 14.252, 'epoch': 5.0}\nSweep Evaluation Accuracy: 0.5858\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▅▅▆▆▇▇██</td></tr><tr><td>eval/loss</td><td>██▄▄▂▂▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>██▁▁▂▂▅▅▆▆</td></tr><tr><td>eval/samples_per_second</td><td>▁▁██▇▇▄▄▃▃</td></tr><tr><td>eval/steps_per_second</td><td>▁▁██▇▇▄▄▃▃</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█</td></tr><tr><td>train/grad_norm</td><td>▁▁▁▁▁▂▃▂▃▄▃▂▃▄▄▄▅▅▃▅▆▄▅▆▃█▅▅▅▇▅▆▆▇▄▆▆▅▅▄</td></tr><tr><td>train/learning_rate</td><td>███████▇▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train/loss</td><td>███████▇▇▅▅▄▅▄▄▄▄▃▅▃▄▂▃▂▂▂▂▂▂▂▃▂▂▂▃▁▂▃▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.5858</td></tr><tr><td>eval/loss</td><td>0.90654</td></tr><tr><td>eval/runtime</td><td>11.0159</td></tr><tr><td>eval/samples_per_second</td><td>453.889</td></tr><tr><td>eval/steps_per_second</td><td>14.252</td></tr><tr><td>total_flos</td><td>1458820915200000.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>3125</td></tr><tr><td>train/grad_norm</td><td>4.11891</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.914</td></tr><tr><td>train_loss</td><td>0.97018</td></tr><tr><td>train_runtime</td><td>704.3684</td></tr><tr><td>train_samples_per_second</td><td>141.971</td></tr><tr><td>train_steps_per_second</td><td>4.437</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">feasible-sweep-25</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/p9ysimmd' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/p9ysimmd</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_232942-p9ysimmd/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fri91lbm with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.111564544178538e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_r: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler: cosine\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw_8bit\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_234140-fri91lbm</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/fri91lbm' target=\"_blank\">fine-sweep-26</a></strong> to <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/sweeps/giymvsf9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/fri91lbm' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/fri91lbm</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n:DefaultFlowCallback\nTensorBoardCallback\nWandbCallback\nSaveBestAcrossSweepsCallback\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "trainable params: 80,811 || all params: 14,431,998 || trainable%: 0.5599\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [390/390 10:06, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.098000</td>\n      <td>1.098127</td>\n      <td>0.366800</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.096900</td>\n      <td>1.097542</td>\n      <td>0.349200</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.094700</td>\n      <td>1.096940</td>\n      <td>0.353200</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.093400</td>\n      <td>1.096509</td>\n      <td>0.360400</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.094700</td>\n      <td>1.096423</td>\n      <td>0.363600</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluation Metrics: {'eval_loss': 1.098126769065857, 'eval_accuracy': 0.3668, 'eval_runtime': 10.9573, 'eval_samples_per_second': 456.318, 'eval_steps_per_second': 14.328, 'epoch': 0.9984}\nEvaluation Metrics: {'eval_loss': 1.0975420475006104, 'eval_accuracy': 0.3492, 'eval_runtime': 10.9793, 'eval_samples_per_second': 455.404, 'eval_steps_per_second': 14.3, 'epoch': 1.9968}\nEvaluation Metrics: {'eval_loss': 1.096940040588379, 'eval_accuracy': 0.3532, 'eval_runtime': 10.9083, 'eval_samples_per_second': 458.366, 'eval_steps_per_second': 14.393, 'epoch': 2.9952}\nEvaluation Metrics: {'eval_loss': 1.096509337425232, 'eval_accuracy': 0.3604, 'eval_runtime': 10.8964, 'eval_samples_per_second': 458.865, 'eval_steps_per_second': 14.408, 'epoch': 3.9936}\nEvaluation Metrics: {'eval_loss': 1.0964232683181763, 'eval_accuracy': 0.3636, 'eval_runtime': 10.9564, 'eval_samples_per_second': 456.353, 'eval_steps_per_second': 14.329, 'epoch': 4.992}\nSweep Evaluation Accuracy: 0.3636\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>██▁▁▃▃▅▅▇▇</td></tr><tr><td>eval/loss</td><td>██▆▆▃▃▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▆▆██▂▂▁▁▆▆</td></tr><tr><td>eval/samples_per_second</td><td>▃▃▁▁▇▇██▃▃</td></tr><tr><td>eval/steps_per_second</td><td>▃▃▁▁▇▇██▃▃</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▄▄▂▅▅▄▄▅▆▂▂▂▄▄█▃▁▁▄▁▂▂▂▅▅▆▆▂▂▃▂▄▄▄▆▃▄▃▂▂</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▆▆████▇▇▇▇▇▇▆▆▆▆▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█████▇▇▇▇▇▆▆▆▇▇▆▅▅▅▅▄▆▅▃▄▂▂▂▂▃▂▂▆▆▅▃▃▁▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.3636</td></tr><tr><td>eval/loss</td><td>1.09642</td></tr><tr><td>eval/runtime</td><td>10.9564</td></tr><tr><td>eval/samples_per_second</td><td>456.353</td></tr><tr><td>eval/steps_per_second</td><td>14.329</td></tr><tr><td>total_flos</td><td>1456486801735680.0</td></tr><tr><td>train/epoch</td><td>4.992</td></tr><tr><td>train/global_step</td><td>390</td></tr><tr><td>train/grad_norm</td><td>0.33368</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>1.0947</td></tr><tr><td>train_loss</td><td>1.09617</td></tr><tr><td>train_runtime</td><td>607.7594</td></tr><tr><td>train_samples_per_second</td><td>164.539</td></tr><tr><td>train_steps_per_second</td><td>0.642</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">fine-sweep-26</strong> at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/fri91lbm' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle/runs/fri91lbm</a><br/> View project at: <a href='https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle' target=\"_blank\">https://wandb.ai/garima440-new-york-university/TinyBert%20with%20GLUE%20on%20Kaggle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241206_234140-fri91lbm/logs</code>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "import torch"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-07T04:29:53.91502Z",
          "iopub.execute_input": "2024-12-07T04:29:53.915767Z",
          "iopub.status.idle": "2024-12-07T04:29:54.35569Z",
          "shell.execute_reply.started": "2024-12-07T04:29:53.915727Z",
          "shell.execute_reply": "2024-12-07T04:29:54.354922Z"
        },
        "id": "wTyjS4PbcJ4o"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "global_best_model_checkpoint = \"./global_best_model\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-07T04:29:57.340331Z",
          "iopub.execute_input": "2024-12-07T04:29:57.341284Z",
          "iopub.status.idle": "2024-12-07T04:29:57.345104Z",
          "shell.execute_reply.started": "2024-12-07T04:29:57.341244Z",
          "shell.execute_reply": "2024-12-07T04:29:57.344203Z"
        },
        "id": "NFKbh5XrcJ4o"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save_pretrained(global_best_model_checkpoint)\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(global_best_model_checkpoint)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-07T04:29:59.527047Z",
          "iopub.execute_input": "2024-12-07T04:29:59.527461Z",
          "iopub.status.idle": "2024-12-07T04:30:00.211195Z",
          "shell.execute_reply.started": "2024-12-07T04:29:59.527427Z",
          "shell.execute_reply": "2024-12-07T04:30:00.21032Z"
        },
        "id": "ml6Gkff6cJ4o",
        "outputId": "8be7e996-0cdb-466c-9b52-223945d1d4bf"
      },
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "('./global_best_model/tokenizer_config.json',\n './global_best_model/special_tokens_map.json',\n './global_best_model/vocab.txt',\n './global_best_model/added_tokens.json',\n './global_best_model/tokenizer.json')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}